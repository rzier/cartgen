{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30383d2f-0f0c-4c64-ba07-c1061cef65d8",
   "metadata": {},
   "source": [
    "# Understanding Autoencoders\n",
    "\n",
    "\n",
    "## Dataset Source\n",
    "\n",
    "- [Kaggle]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835d253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device='cuda'\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"{device=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "208fcda3-fb6d-4d3d-acf0-edaf0a07cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dataset From Source...\n",
      "+ '[' '!' -d dataset ']'\n",
      "+ echo 'Dataset Directory already exist!'\n",
      "Dataset Directory already exist!\n"
     ]
    }
   ],
   "source": [
    "!bash dataset_fetch.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "998923ed-7651-4daf-8d8b-78f636960975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Cell\n",
    "\n",
    "\n",
    "def helper_imageGrid(image_paths, cols=4):\n",
    "    img_count = len(image_paths)\n",
    "    rows = math.ceil(img_count / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 20))\n",
    "    irow, icol = 0, 0\n",
    "    for path in image_paths:\n",
    "        ax = axes[irow][icol]\n",
    "        ax.imshow(Image.open(path))\n",
    "        title = path.split(\"/\")[-2]\n",
    "        #ax.title(path)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        icol += 1\n",
    "        if icol % cols == 0:\n",
    "            icol = 0\n",
    "            irow += 1\n",
    "\n",
    "        \n",
    "    \n",
    "    return fig\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def helper_fetch_localmodel(mname=\"autoencoder\", device=device):\n",
    "    max_name = None\n",
    "    max_num = 0\n",
    "    for x in os.listdir():\n",
    "        if a := re.match(f\"{mname}_\\\\d+\", x):\n",
    "            name = a.group()\n",
    "            num = int(name.split(\"_\")[-1])\n",
    "            max_num = num if max_num < num else max_num\n",
    "    if max_num > 0:\n",
    "        return max_num, torch.load(f\"model/{mname}_{max_num}\", map_location=torch.device(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9cedefe-63ed-490c-81e5-ada3c922cd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of Images:  {(300, 300)}\n",
      "Count of Images:  1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "image_paths = [ f\"dataset/GAID/Soul/{x}\" for x in os.listdir(\"dataset/GAID/Soul\") ]\n",
    "\n",
    "\n",
    "sizes = set()\n",
    "for x in image_paths:\n",
    "    img = Image.open(x)\n",
    "    sizes.add(img.size)\n",
    "    img.close()\n",
    "\n",
    "print(\"Sizes of Images: \", sizes)\n",
    "print(\"Count of Images: \", len(image_paths))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "48235302-dea9-4055-bdf4-a6b36d1a9bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is Available!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "100x100 --> 10x10 --> 10 --> 10x10 --> 100x100\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(100**2, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100**2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ReconstructionLoss(reproduced, original): \n",
    "    return torch.sum((original - reproduced)**2) / len(original)\n",
    "\n",
    "print(f\"{device} is Available!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c8ed8a-cec3-4d2d-b824-ccafe1f25702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def todata(path):\n",
    "    image = Image.open(path).convert(\"L\").resize((100, 100))\n",
    "    tensor = transforms.ToTensor()(image)\n",
    "    tensor = nn.Flatten(0)(tensor)\n",
    "    image.close()\n",
    "    return tensor\n",
    "    \n",
    "def toimg(data):\n",
    "    data = nn.Sigmoid()(data.view(100, 100)) * 255\n",
    "    return np.uint8(data.detach().numpy())\n",
    "    \n",
    "auto = Autoencoder().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8b740c-cdf5-4422-ba0c-b3da3d99f813",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib tk\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "raw_img = fig.add_axes([0, 0.5, 0.5 - 0.02, 0.5 - 0.02])\n",
    "trans_img = fig.add_axes([0.5, 0.5, 0.5 - 0.02, 0.5 - 0.02])\n",
    "\n",
    "loss_ax = fig.add_axes([0, 0, 1 - 0.02, 0.5 - 0.02])\n",
    "\n",
    "raw_img.axis(\"off\")\n",
    "trans_img.axis(\"off\")\n",
    "loss_ax.axis(\"off\")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "loss_ax.set_xlim(left=0, right=epochs)\n",
    "optimizer = torch.optim.Adam(auto.parameters(),lr=0.001)\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    sample_path = random.choice(image_paths)\n",
    "    sample_data = todata(sample_path)\n",
    "    sample_img = toimg(sample_data)\n",
    "\n",
    "    raw_img.imshow(sample_img, cmap=\"ocean_r\")\n",
    "    timg = toimg(auto(sample_data.to(device)).to(\"cpu\"))\n",
    "    trans_img.imshow(timg, cmap=\"ocean_r\")\n",
    "    \n",
    "\n",
    "\n",
    "    for path in image_paths:\n",
    "        optimizer.zero_grad()\n",
    "        sample = todata(path).to(device)\n",
    "        op = auto(sample).to(device)\n",
    "        loss = ReconstructionLoss(sample, op)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_ax.plot(epoch, loss.to(\"cpu\").item(), \"ro\")\n",
    "    fig.canvas.flush_events()\n",
    "    fig.show()\n",
    "    print(f\"{epoch} done, {loss.to(\"cpu\").item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7b19f-be7f-443d-8087-4efbd5061626",
   "metadata": {},
   "source": [
    "show_count = 10\n",
    "\n",
    "fig, axes = plt.subplots(show_count, 2, figsize=(10, show_count * 5))\n",
    "\n",
    "for i, path in enumerate(image_paths[:show_count]):\n",
    "    data = todata(path).to(device)\n",
    "    infer = auto(data).to(\"cpu\")\n",
    "    data = data.to(\"cpu\")\n",
    "    axes[i][0].imshow(toimg(data), cmap=\"gray\")\n",
    "    axes[i][0].axis(\"off\")\n",
    "    axes[i][1].imshow(toimg(infer), cmap=\"gray\")\n",
    "    axes[i][1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d374a26-7535-4cfb-b384-00ecab347924",
   "metadata": {},
   "source": [
    "# Understanding and creating a Convolutional Autoencoer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d8a9cbc-82e4-41a9-95f1-d5fbaa2f6327",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=10, out_channels=5, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=5, out_channels=5, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Flatten(1)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(1, (5, 3, 3)),\n",
    "            nn.UpsamplingBilinear2d(None, (3, 3)),\n",
    "            nn.ConvTranspose2d(in_channels=5, out_channels=5, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.UpsamplingBilinear2d(None, (3, 3)),\n",
    "            nn.ConvTranspose2d(in_channels=5, out_channels=10, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.UpsamplingBilinear2d(None, (3, 3)),\n",
    "            nn.ConvTranspose2d(in_channels=10, out_channels=1, kernel_size=3, padding=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f8cf82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTensor(path):\n",
    "    img = Image.open(path).resize((99, 99)).convert(\"L\")\n",
    "    data = transforms.ToTensor()(img)\n",
    "    img.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def toimg(data):\n",
    "   return np.uint8(data.view(99, 99).detach().numpy() * 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16fd6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CoverArtsDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.paths = image_paths\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return prepareTensor(self.paths[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7065e637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n",
      "[INFO]: Model Loaded with epoch=838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21300/3161432489.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return max_num, torch.load(f\"{mname}_{max_num}\", map_location=torch.device(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Epoch Done: 839/-1\n",
      "Number Of Epoch Done: 840/-1\n",
      "Number Of Epoch Done: 841/-1\n",
      "Number Of Epoch Done: 842/-1\n",
      "Number Of Epoch Done: 843/-1\n",
      "Number Of Epoch Done: 844/-1\n",
      "Number Of Epoch Done: 845/-1\n",
      "Number Of Epoch Done: 846/-1\n",
      "Number Of Epoch Done: 847/-1\n",
      "Number Of Epoch Done: 848/-1\n",
      "Number Of Epoch Done: 849/-1\n",
      "Number Of Epoch Done: 850/-1\n",
      "Number Of Epoch Done: 851/-1\n",
      "Number Of Epoch Done: 852/-1\n",
      "Number Of Epoch Done: 853/-1\n",
      "Number Of Epoch Done: 854/-1\n",
      "Number Of Epoch Done: 855/-1\n",
      "Number Of Epoch Done: 856/-1\n",
      "Number Of Epoch Done: 857/-1\n",
      "Number Of Epoch Done: 858/-1\n",
      "Number Of Epoch Done: 859/-1\n",
      "Number Of Epoch Done: 860/-1\n",
      "Number Of Epoch Done: 861/-1\n",
      "Number Of Epoch Done: 862/-1\n",
      "Number Of Epoch Done: 863/-1\n",
      "Number Of Epoch Done: 864/-1\n",
      "Number Of Epoch Done: 865/-1\n",
      "Number Of Epoch Done: 866/-1\n",
      "Number Of Epoch Done: 867/-1\n",
      "Number Of Epoch Done: 868/-1\n",
      "Number Of Epoch Done: 869/-1\n",
      "Number Of Epoch Done: 870/-1\n",
      "Number Of Epoch Done: 871/-1\n",
      "Number Of Epoch Done: 872/-1\n",
      "Number Of Epoch Done: 873/-1\n",
      "Number Of Epoch Done: 874/-1\n",
      "Number Of Epoch Done: 875/-1\n",
      "Number Of Epoch Done: 876/-1\n",
      "Number Of Epoch Done: 877/-1\n",
      "Number Of Epoch Done: 878/-1\n",
      "Number Of Epoch Done: 879/-1\n",
      "Number Of Epoch Done: 880/-1\n",
      "Number Of Epoch Done: 881/-1\n",
      "Number Of Epoch Done: 882/-1\n",
      "Number Of Epoch Done: 883/-1\n",
      "Number Of Epoch Done: 884/-1\n",
      "Number Of Epoch Done: 885/-1\n",
      "Number Of Epoch Done: 886/-1\n",
      "Number Of Epoch Done: 887/-1\n",
      "Number Of Epoch Done: 888/-1\n",
      "Number Of Epoch Done: 889/-1\n",
      "Number Of Epoch Done: 890/-1\n",
      "Number Of Epoch Done: 891/-1\n",
      "Number Of Epoch Done: 892/-1\n",
      "Number Of Epoch Done: 893/-1\n",
      "Number Of Epoch Done: 894/-1\n",
      "Number Of Epoch Done: 895/-1\n",
      "Number Of Epoch Done: 896/-1\n",
      "Number Of Epoch Done: 897/-1\n",
      "Number Of Epoch Done: 898/-1\n",
      "Number Of Epoch Done: 899/-1\n",
      "Number Of Epoch Done: 900/-1\n",
      "Number Of Epoch Done: 901/-1\n",
      "Number Of Epoch Done: 902/-1\n",
      "Number Of Epoch Done: 903/-1\n",
      "Number Of Epoch Done: 904/-1\n",
      "Number Of Epoch Done: 905/-1\n",
      "Number Of Epoch Done: 906/-1\n",
      "Number Of Epoch Done: 907/-1\n",
      "Number Of Epoch Done: 908/-1\n",
      "Number Of Epoch Done: 909/-1\n",
      "Number Of Epoch Done: 910/-1\n",
      "Number Of Epoch Done: 911/-1\n",
      "Number Of Epoch Done: 912/-1\n",
      "Number Of Epoch Done: 913/-1\n",
      "Number Of Epoch Done: 914/-1\n",
      "Number Of Epoch Done: 915/-1\n",
      "Number Of Epoch Done: 916/-1\n",
      "Number Of Epoch Done: 917/-1\n",
      "Number Of Epoch Done: 918/-1\n",
      "Number Of Epoch Done: 919/-1\n",
      "Number Of Epoch Done: 920/-1\n",
      "Number Of Epoch Done: 921/-1\n",
      "Number Of Epoch Done: 922/-1\n",
      "Number Of Epoch Done: 923/-1\n",
      "Number Of Epoch Done: 924/-1\n",
      "Number Of Epoch Done: 925/-1\n",
      "Number Of Epoch Done: 926/-1\n",
      "Number Of Epoch Done: 927/-1\n",
      "Number Of Epoch Done: 928/-1\n",
      "Number Of Epoch Done: 929/-1\n",
      "Number Of Epoch Done: 930/-1\n",
      "Number Of Epoch Done: 931/-1\n",
      "Number Of Epoch Done: 932/-1\n",
      "Number Of Epoch Done: 933/-1\n",
      "Number Of Epoch Done: 934/-1\n",
      "Number Of Epoch Done: 935/-1\n",
      "Number Of Epoch Done: 936/-1\n",
      "Number Of Epoch Done: 937/-1\n",
      "Number Of Epoch Done: 938/-1\n",
      "Number Of Epoch Done: 939/-1\n",
      "Number Of Epoch Done: 940/-1\n",
      "Number Of Epoch Done: 941/-1\n",
      "Number Of Epoch Done: 942/-1\n",
      "Number Of Epoch Done: 943/-1\n",
      "Number Of Epoch Done: 944/-1\n",
      "Number Of Epoch Done: 945/-1\n",
      "Number Of Epoch Done: 946/-1\n",
      "Number Of Epoch Done: 947/-1\n",
      "Number Of Epoch Done: 948/-1\n",
      "Number Of Epoch Done: 949/-1\n",
      "Number Of Epoch Done: 950/-1\n",
      "Number Of Epoch Done: 951/-1\n",
      "Number Of Epoch Done: 952/-1\n",
      "Number Of Epoch Done: 953/-1\n",
      "Number Of Epoch Done: 954/-1\n",
      "Number Of Epoch Done: 955/-1\n",
      "Number Of Epoch Done: 956/-1\n",
      "Number Of Epoch Done: 957/-1\n",
      "Number Of Epoch Done: 958/-1\n",
      "Number Of Epoch Done: 959/-1\n",
      "Number Of Epoch Done: 960/-1\n",
      "Number Of Epoch Done: 961/-1\n",
      "Number Of Epoch Done: 962/-1\n",
      "Number Of Epoch Done: 963/-1\n",
      "Number Of Epoch Done: 964/-1\n",
      "Number Of Epoch Done: 965/-1\n",
      "Number Of Epoch Done: 966/-1\n",
      "Number Of Epoch Done: 967/-1\n",
      "Number Of Epoch Done: 968/-1\n",
      "Number Of Epoch Done: 969/-1\n",
      "Number Of Epoch Done: 970/-1\n",
      "Number Of Epoch Done: 971/-1\n",
      "Number Of Epoch Done: 972/-1\n",
      "Number Of Epoch Done: 973/-1\n",
      "Number Of Epoch Done: 974/-1\n",
      "Number Of Epoch Done: 975/-1\n",
      "Number Of Epoch Done: 976/-1\n",
      "Number Of Epoch Done: 977/-1\n",
      "Number Of Epoch Done: 978/-1\n",
      "Number Of Epoch Done: 979/-1\n",
      "Number Of Epoch Done: 980/-1\n",
      "Number Of Epoch Done: 981/-1\n",
      "Number Of Epoch Done: 982/-1\n",
      "Number Of Epoch Done: 983/-1\n",
      "Number Of Epoch Done: 984/-1\n",
      "Number Of Epoch Done: 985/-1\n",
      "Number Of Epoch Done: 986/-1\n",
      "Number Of Epoch Done: 987/-1\n",
      "Number Of Epoch Done: 988/-1\n",
      "Number Of Epoch Done: 989/-1\n",
      "Number Of Epoch Done: 990/-1\n",
      "Number Of Epoch Done: 991/-1\n",
      "Number Of Epoch Done: 992/-1\n",
      "Number Of Epoch Done: 993/-1\n",
      "Number Of Epoch Done: 994/-1\n",
      "Number Of Epoch Done: 995/-1\n",
      "Number Of Epoch Done: 996/-1\n",
      "Number Of Epoch Done: 997/-1\n",
      "Number Of Epoch Done: 998/-1\n",
      "Number Of Epoch Done: 999/-1\n",
      "Number Of Epoch Done: 1000/-1\n",
      "Number Of Epoch Done: 1001/-1\n",
      "Number Of Epoch Done: 1002/-1\n",
      "Number Of Epoch Done: 1003/-1\n",
      "Number Of Epoch Done: 1004/-1\n",
      "Number Of Epoch Done: 1005/-1\n",
      "Number Of Epoch Done: 1006/-1\n",
      "Number Of Epoch Done: 1007/-1\n",
      "Number Of Epoch Done: 1008/-1\n",
      "Number Of Epoch Done: 1009/-1\n",
      "Number Of Epoch Done: 1010/-1\n",
      "Number Of Epoch Done: 1011/-1\n",
      "Number Of Epoch Done: 1012/-1\n",
      "Number Of Epoch Done: 1013/-1\n",
      "Number Of Epoch Done: 1014/-1\n",
      "Number Of Epoch Done: 1015/-1\n",
      "Number Of Epoch Done: 1016/-1\n",
      "Number Of Epoch Done: 1017/-1\n",
      "Number Of Epoch Done: 1018/-1\n",
      "Number Of Epoch Done: 1019/-1\n",
      "Number Of Epoch Done: 1020/-1\n",
      "Number Of Epoch Done: 1021/-1\n",
      "Number Of Epoch Done: 1022/-1\n",
      "Number Of Epoch Done: 1023/-1\n",
      "Number Of Epoch Done: 1024/-1\n",
      "Number Of Epoch Done: 1025/-1\n",
      "Number Of Epoch Done: 1026/-1\n",
      "Number Of Epoch Done: 1027/-1\n",
      "Number Of Epoch Done: 1028/-1\n",
      "Number Of Epoch Done: 1029/-1\n",
      "Number Of Epoch Done: 1030/-1\n",
      "Number Of Epoch Done: 1031/-1\n",
      "Number Of Epoch Done: 1032/-1\n",
      "Number Of Epoch Done: 1033/-1\n",
      "Number Of Epoch Done: 1034/-1\n",
      "Number Of Epoch Done: 1035/-1\n",
      "Number Of Epoch Done: 1036/-1\n",
      "Number Of Epoch Done: 1037/-1\n",
      "Number Of Epoch Done: 1038/-1\n",
      "Number Of Epoch Done: 1039/-1\n",
      "Number Of Epoch Done: 1040/-1\n",
      "Number Of Epoch Done: 1041/-1\n",
      "Number Of Epoch Done: 1042/-1\n",
      "Number Of Epoch Done: 1043/-1\n",
      "Number Of Epoch Done: 1044/-1\n",
      "Number Of Epoch Done: 1045/-1\n",
      "Number Of Epoch Done: 1046/-1\n",
      "Number Of Epoch Done: 1047/-1\n",
      "Number Of Epoch Done: 1048/-1\n",
      "Number Of Epoch Done: 1049/-1\n",
      "Number Of Epoch Done: 1050/-1\n",
      "Number Of Epoch Done: 1051/-1\n",
      "Number Of Epoch Done: 1052/-1\n",
      "Number Of Epoch Done: 1053/-1\n",
      "Number Of Epoch Done: 1054/-1\n",
      "Number Of Epoch Done: 1055/-1\n",
      "Number Of Epoch Done: 1056/-1\n",
      "Number Of Epoch Done: 1057/-1\n",
      "Number Of Epoch Done: 1058/-1\n",
      "Number Of Epoch Done: 1059/-1\n",
      "Number Of Epoch Done: 1060/-1\n",
      "Number Of Epoch Done: 1061/-1\n",
      "Number Of Epoch Done: 1062/-1\n",
      "Number Of Epoch Done: 1063/-1\n",
      "Number Of Epoch Done: 1064/-1\n",
      "Number Of Epoch Done: 1065/-1\n",
      "Number Of Epoch Done: 1066/-1\n",
      "Number Of Epoch Done: 1067/-1\n",
      "Number Of Epoch Done: 1068/-1\n",
      "Number Of Epoch Done: 1069/-1\n",
      "Number Of Epoch Done: 1070/-1\n",
      "Number Of Epoch Done: 1071/-1\n",
      "Number Of Epoch Done: 1072/-1\n",
      "Number Of Epoch Done: 1073/-1\n",
      "Number Of Epoch Done: 1074/-1\n",
      "Number Of Epoch Done: 1075/-1\n",
      "Number Of Epoch Done: 1076/-1\n",
      "Number Of Epoch Done: 1077/-1\n",
      "Number Of Epoch Done: 1078/-1\n",
      "Number Of Epoch Done: 1079/-1\n",
      "Number Of Epoch Done: 1080/-1\n",
      "Number Of Epoch Done: 1081/-1\n",
      "Number Of Epoch Done: 1082/-1\n",
      "Number Of Epoch Done: 1083/-1\n",
      "Number Of Epoch Done: 1084/-1\n",
      "Number Of Epoch Done: 1085/-1\n",
      "Number Of Epoch Done: 1086/-1\n",
      "Number Of Epoch Done: 1087/-1\n",
      "Number Of Epoch Done: 1088/-1\n",
      "Number Of Epoch Done: 1089/-1\n",
      "Number Of Epoch Done: 1090/-1\n",
      "Number Of Epoch Done: 1091/-1\n",
      "Number Of Epoch Done: 1092/-1\n",
      "Number Of Epoch Done: 1093/-1\n",
      "Number Of Epoch Done: 1094/-1\n",
      "Number Of Epoch Done: 1095/-1\n",
      "Number Of Epoch Done: 1096/-1\n",
      "Number Of Epoch Done: 1097/-1\n",
      "Number Of Epoch Done: 1098/-1\n",
      "Number Of Epoch Done: 1099/-1\n",
      "Number Of Epoch Done: 1100/-1\n",
      "Number Of Epoch Done: 1101/-1\n",
      "Number Of Epoch Done: 1102/-1\n",
      "Number Of Epoch Done: 1103/-1\n",
      "Number Of Epoch Done: 1104/-1\n",
      "Number Of Epoch Done: 1105/-1\n",
      "Number Of Epoch Done: 1106/-1\n",
      "Number Of Epoch Done: 1107/-1\n",
      "Number Of Epoch Done: 1108/-1\n",
      "Number Of Epoch Done: 1109/-1\n",
      "Number Of Epoch Done: 1110/-1\n",
      "Number Of Epoch Done: 1111/-1\n",
      "Number Of Epoch Done: 1112/-1\n",
      "Number Of Epoch Done: 1113/-1\n",
      "Number Of Epoch Done: 1114/-1\n",
      "Number Of Epoch Done: 1115/-1\n",
      "Number Of Epoch Done: 1116/-1\n",
      "Number Of Epoch Done: 1117/-1\n",
      "Number Of Epoch Done: 1118/-1\n",
      "Number Of Epoch Done: 1119/-1\n",
      "Number Of Epoch Done: 1120/-1\n",
      "Number Of Epoch Done: 1121/-1\n",
      "Number Of Epoch Done: 1122/-1\n",
      "Number Of Epoch Done: 1123/-1\n",
      "Number Of Epoch Done: 1124/-1\n",
      "Number Of Epoch Done: 1125/-1\n",
      "Number Of Epoch Done: 1126/-1\n",
      "Number Of Epoch Done: 1127/-1\n",
      "Number Of Epoch Done: 1128/-1\n",
      "Number Of Epoch Done: 1129/-1\n",
      "Number Of Epoch Done: 1130/-1\n",
      "Number Of Epoch Done: 1131/-1\n",
      "Number Of Epoch Done: 1132/-1\n",
      "Number Of Epoch Done: 1133/-1\n",
      "Number Of Epoch Done: 1134/-1\n",
      "Number Of Epoch Done: 1135/-1\n",
      "Number Of Epoch Done: 1136/-1\n",
      "Number Of Epoch Done: 1137/-1\n",
      "Number Of Epoch Done: 1138/-1\n",
      "Number Of Epoch Done: 1139/-1\n",
      "Number Of Epoch Done: 1140/-1\n",
      "Number Of Epoch Done: 1141/-1\n",
      "Number Of Epoch Done: 1142/-1\n",
      "Number Of Epoch Done: 1143/-1\n",
      "Number Of Epoch Done: 1144/-1\n",
      "Number Of Epoch Done: 1145/-1\n",
      "Number Of Epoch Done: 1146/-1\n",
      "Number Of Epoch Done: 1147/-1\n",
      "Number Of Epoch Done: 1148/-1\n",
      "Number Of Epoch Done: 1149/-1\n",
      "Number Of Epoch Done: 1150/-1\n",
      "Number Of Epoch Done: 1151/-1\n",
      "Number Of Epoch Done: 1152/-1\n",
      "Number Of Epoch Done: 1153/-1\n",
      "Number Of Epoch Done: 1154/-1\n",
      "Number Of Epoch Done: 1155/-1\n",
      "Number Of Epoch Done: 1156/-1\n",
      "Number Of Epoch Done: 1157/-1\n",
      "Number Of Epoch Done: 1158/-1\n",
      "Number Of Epoch Done: 1159/-1\n",
      "Number Of Epoch Done: 1160/-1\n",
      "Number Of Epoch Done: 1161/-1\n",
      "Number Of Epoch Done: 1162/-1\n",
      "Number Of Epoch Done: 1163/-1\n",
      "Number Of Epoch Done: 1164/-1\n",
      "Number Of Epoch Done: 1165/-1\n",
      "Number Of Epoch Done: 1166/-1\n",
      "Number Of Epoch Done: 1167/-1\n",
      "Number Of Epoch Done: 1168/-1\n",
      "Number Of Epoch Done: 1169/-1\n",
      "Number Of Epoch Done: 1170/-1\n",
      "Number Of Epoch Done: 1171/-1\n",
      "Number Of Epoch Done: 1172/-1\n",
      "Number Of Epoch Done: 1173/-1\n",
      "Number Of Epoch Done: 1174/-1\n",
      "Number Of Epoch Done: 1175/-1\n",
      "Number Of Epoch Done: 1176/-1\n",
      "Number Of Epoch Done: 1177/-1\n",
      "Number Of Epoch Done: 1178/-1\n",
      "Number Of Epoch Done: 1179/-1\n",
      "Number Of Epoch Done: 1180/-1\n",
      "Number Of Epoch Done: 1181/-1\n",
      "Number Of Epoch Done: 1182/-1\n",
      "Number Of Epoch Done: 1183/-1\n",
      "Number Of Epoch Done: 1184/-1\n",
      "Number Of Epoch Done: 1185/-1\n",
      "Number Of Epoch Done: 1186/-1\n",
      "Number Of Epoch Done: 1187/-1\n",
      "Number Of Epoch Done: 1188/-1\n",
      "Number Of Epoch Done: 1189/-1\n",
      "Number Of Epoch Done: 1190/-1\n",
      "Number Of Epoch Done: 1191/-1\n",
      "Number Of Epoch Done: 1192/-1\n",
      "Number Of Epoch Done: 1193/-1\n",
      "Number Of Epoch Done: 1194/-1\n",
      "Number Of Epoch Done: 1195/-1\n",
      "Number Of Epoch Done: 1196/-1\n",
      "Number Of Epoch Done: 1197/-1\n",
      "Number Of Epoch Done: 1198/-1\n",
      "Number Of Epoch Done: 1199/-1\n",
      "Number Of Epoch Done: 1200/-1\n",
      "Number Of Epoch Done: 1201/-1\n",
      "Number Of Epoch Done: 1202/-1\n",
      "Number Of Epoch Done: 1203/-1\n",
      "Number Of Epoch Done: 1204/-1\n",
      "Number Of Epoch Done: 1205/-1\n",
      "Number Of Epoch Done: 1206/-1\n",
      "Number Of Epoch Done: 1207/-1\n",
      "Number Of Epoch Done: 1208/-1\n",
      "Number Of Epoch Done: 1209/-1\n",
      "Number Of Epoch Done: 1210/-1\n",
      "Number Of Epoch Done: 1211/-1\n",
      "Number Of Epoch Done: 1212/-1\n",
      "Number Of Epoch Done: 1213/-1\n",
      "Number Of Epoch Done: 1214/-1\n",
      "Number Of Epoch Done: 1215/-1\n",
      "Number Of Epoch Done: 1216/-1\n",
      "Number Of Epoch Done: 1217/-1\n",
      "Number Of Epoch Done: 1218/-1\n",
      "Number Of Epoch Done: 1219/-1\n",
      "Number Of Epoch Done: 1220/-1\n",
      "Number Of Epoch Done: 1221/-1\n",
      "Number Of Epoch Done: 1222/-1\n",
      "Number Of Epoch Done: 1223/-1\n",
      "Number Of Epoch Done: 1224/-1\n",
      "Number Of Epoch Done: 1225/-1\n",
      "Number Of Epoch Done: 1226/-1\n",
      "Number Of Epoch Done: 1227/-1\n",
      "Number Of Epoch Done: 1228/-1\n",
      "Number Of Epoch Done: 1229/-1\n",
      "Number Of Epoch Done: 1230/-1\n",
      "Number Of Epoch Done: 1231/-1\n",
      "Number Of Epoch Done: 1232/-1\n",
      "Number Of Epoch Done: 1233/-1\n",
      "Number Of Epoch Done: 1234/-1\n",
      "Number Of Epoch Done: 1235/-1\n",
      "Number Of Epoch Done: 1236/-1\n",
      "Number Of Epoch Done: 1237/-1\n",
      "Number Of Epoch Done: 1238/-1\n",
      "Number Of Epoch Done: 1239/-1\n",
      "Number Of Epoch Done: 1240/-1\n",
      "Number Of Epoch Done: 1241/-1\n",
      "Number Of Epoch Done: 1242/-1\n",
      "Number Of Epoch Done: 1243/-1\n",
      "Number Of Epoch Done: 1244/-1\n",
      "Number Of Epoch Done: 1245/-1\n",
      "Number Of Epoch Done: 1246/-1\n",
      "Number Of Epoch Done: 1247/-1\n",
      "Number Of Epoch Done: 1248/-1\n",
      "Number Of Epoch Done: 1249/-1\n",
      "Number Of Epoch Done: 1250/-1\n",
      "Number Of Epoch Done: 1251/-1\n",
      "Number Of Epoch Done: 1252/-1\n",
      "Number Of Epoch Done: 1253/-1\n",
      "Number Of Epoch Done: 1254/-1\n",
      "Number Of Epoch Done: 1255/-1\n",
      "Number Of Epoch Done: 1256/-1\n",
      "Number Of Epoch Done: 1257/-1\n",
      "Number Of Epoch Done: 1258/-1\n",
      "Number Of Epoch Done: 1259/-1\n",
      "Number Of Epoch Done: 1260/-1\n",
      "Number Of Epoch Done: 1261/-1\n",
      "Number Of Epoch Done: 1262/-1\n",
      "Number Of Epoch Done: 1263/-1\n",
      "Number Of Epoch Done: 1264/-1\n",
      "Number Of Epoch Done: 1265/-1\n",
      "Number Of Epoch Done: 1266/-1\n",
      "Number Of Epoch Done: 1267/-1\n",
      "Number Of Epoch Done: 1268/-1\n",
      "Number Of Epoch Done: 1269/-1\n",
      "Number Of Epoch Done: 1270/-1\n",
      "Number Of Epoch Done: 1271/-1\n",
      "Number Of Epoch Done: 1272/-1\n",
      "Number Of Epoch Done: 1273/-1\n",
      "Number Of Epoch Done: 1274/-1\n",
      "Number Of Epoch Done: 1275/-1\n",
      "Number Of Epoch Done: 1276/-1\n",
      "Number Of Epoch Done: 1277/-1\n",
      "Number Of Epoch Done: 1278/-1\n",
      "Number Of Epoch Done: 1279/-1\n",
      "Number Of Epoch Done: 1280/-1\n",
      "Number Of Epoch Done: 1281/-1\n",
      "Number Of Epoch Done: 1282/-1\n",
      "Number Of Epoch Done: 1283/-1\n",
      "Number Of Epoch Done: 1284/-1\n",
      "Number Of Epoch Done: 1285/-1\n",
      "Number Of Epoch Done: 1286/-1\n",
      "Number Of Epoch Done: 1287/-1\n",
      "Number Of Epoch Done: 1288/-1\n",
      "Number Of Epoch Done: 1289/-1\n",
      "Number Of Epoch Done: 1290/-1\n",
      "Number Of Epoch Done: 1291/-1\n",
      "Number Of Epoch Done: 1292/-1\n",
      "Number Of Epoch Done: 1293/-1\n",
      "Number Of Epoch Done: 1294/-1\n",
      "Number Of Epoch Done: 1295/-1\n",
      "Number Of Epoch Done: 1296/-1\n",
      "Number Of Epoch Done: 1297/-1\n",
      "Number Of Epoch Done: 1298/-1\n",
      "Number Of Epoch Done: 1299/-1\n",
      "Number Of Epoch Done: 1300/-1\n",
      "Number Of Epoch Done: 1301/-1\n",
      "Number Of Epoch Done: 1302/-1\n",
      "Number Of Epoch Done: 1303/-1\n",
      "Number Of Epoch Done: 1304/-1\n",
      "Number Of Epoch Done: 1305/-1\n",
      "Number Of Epoch Done: 1306/-1\n",
      "Number Of Epoch Done: 1307/-1\n",
      "Number Of Epoch Done: 1308/-1\n",
      "Number Of Epoch Done: 1309/-1\n",
      "Number Of Epoch Done: 1310/-1\n",
      "Number Of Epoch Done: 1311/-1\n",
      "Number Of Epoch Done: 1312/-1\n",
      "Number Of Epoch Done: 1313/-1\n",
      "Number Of Epoch Done: 1314/-1\n",
      "Number Of Epoch Done: 1315/-1\n",
      "Number Of Epoch Done: 1316/-1\n",
      "Number Of Epoch Done: 1317/-1\n",
      "Number Of Epoch Done: 1318/-1\n",
      "Number Of Epoch Done: 1319/-1\n",
      "Number Of Epoch Done: 1320/-1\n",
      "Number Of Epoch Done: 1321/-1\n",
      "Number Of Epoch Done: 1322/-1\n",
      "Number Of Epoch Done: 1323/-1\n",
      "Number Of Epoch Done: 1324/-1\n",
      "Number Of Epoch Done: 1325/-1\n",
      "Number Of Epoch Done: 1326/-1\n",
      "Number Of Epoch Done: 1327/-1\n",
      "Number Of Epoch Done: 1328/-1\n",
      "Number Of Epoch Done: 1329/-1\n",
      "Number Of Epoch Done: 1330/-1\n",
      "Number Of Epoch Done: 1331/-1\n",
      "Number Of Epoch Done: 1332/-1\n",
      "Number Of Epoch Done: 1333/-1\n",
      "Number Of Epoch Done: 1334/-1\n",
      "Number Of Epoch Done: 1335/-1\n",
      "Number Of Epoch Done: 1336/-1\n",
      "Number Of Epoch Done: 1337/-1\n",
      "Number Of Epoch Done: 1338/-1\n",
      "Number Of Epoch Done: 1339/-1\n",
      "Number Of Epoch Done: 1340/-1\n",
      "Number Of Epoch Done: 1341/-1\n",
      "Number Of Epoch Done: 1342/-1\n",
      "Number Of Epoch Done: 1343/-1\n",
      "Number Of Epoch Done: 1344/-1\n",
      "Number Of Epoch Done: 1345/-1\n",
      "Number Of Epoch Done: 1346/-1\n",
      "Number Of Epoch Done: 1347/-1\n",
      "Number Of Epoch Done: 1348/-1\n",
      "Number Of Epoch Done: 1349/-1\n",
      "Number Of Epoch Done: 1350/-1\n",
      "Number Of Epoch Done: 1351/-1\n",
      "Number Of Epoch Done: 1352/-1\n",
      "Number Of Epoch Done: 1353/-1\n",
      "Number Of Epoch Done: 1354/-1\n",
      "Number Of Epoch Done: 1355/-1\n",
      "Number Of Epoch Done: 1356/-1\n",
      "Number Of Epoch Done: 1357/-1\n",
      "Number Of Epoch Done: 1358/-1\n",
      "Number Of Epoch Done: 1359/-1\n",
      "Number Of Epoch Done: 1360/-1\n",
      "Number Of Epoch Done: 1361/-1\n",
      "Number Of Epoch Done: 1362/-1\n",
      "Number Of Epoch Done: 1363/-1\n",
      "Number Of Epoch Done: 1364/-1\n",
      "Number Of Epoch Done: 1365/-1\n",
      "Number Of Epoch Done: 1366/-1\n",
      "Number Of Epoch Done: 1367/-1\n",
      "Number Of Epoch Done: 1368/-1\n",
      "Number Of Epoch Done: 1369/-1\n",
      "Number Of Epoch Done: 1370/-1\n",
      "Number Of Epoch Done: 1371/-1\n",
      "Number Of Epoch Done: 1372/-1\n",
      "Number Of Epoch Done: 1373/-1\n",
      "Number Of Epoch Done: 1374/-1\n",
      "Number Of Epoch Done: 1375/-1\n",
      "Number Of Epoch Done: 1376/-1\n",
      "Number Of Epoch Done: 1377/-1\n",
      "Number Of Epoch Done: 1378/-1\n",
      "Number Of Epoch Done: 1379/-1\n",
      "Number Of Epoch Done: 1380/-1\n",
      "Number Of Epoch Done: 1381/-1\n",
      "Number Of Epoch Done: 1382/-1\n",
      "Number Of Epoch Done: 1383/-1\n",
      "Number Of Epoch Done: 1384/-1\n",
      "Number Of Epoch Done: 1385/-1\n",
      "Number Of Epoch Done: 1386/-1\n",
      "Number Of Epoch Done: 1387/-1\n",
      "Number Of Epoch Done: 1388/-1\n",
      "Number Of Epoch Done: 1389/-1\n",
      "Number Of Epoch Done: 1390/-1\n",
      "Number Of Epoch Done: 1391/-1\n",
      "Number Of Epoch Done: 1392/-1\n",
      "Number Of Epoch Done: 1393/-1\n",
      "Number Of Epoch Done: 1394/-1\n",
      "Number Of Epoch Done: 1395/-1\n",
      "Number Of Epoch Done: 1396/-1\n",
      "Number Of Epoch Done: 1397/-1\n",
      "Number Of Epoch Done: 1398/-1\n",
      "Number Of Epoch Done: 1399/-1\n",
      "Number Of Epoch Done: 1400/-1\n",
      "Number Of Epoch Done: 1401/-1\n",
      "Number Of Epoch Done: 1402/-1\n",
      "Number Of Epoch Done: 1403/-1\n",
      "Number Of Epoch Done: 1404/-1\n",
      "Number Of Epoch Done: 1405/-1\n",
      "Number Of Epoch Done: 1406/-1\n",
      "Number Of Epoch Done: 1407/-1\n",
      "Number Of Epoch Done: 1408/-1\n",
      "Number Of Epoch Done: 1409/-1\n",
      "Number Of Epoch Done: 1410/-1\n",
      "Number Of Epoch Done: 1411/-1\n",
      "Number Of Epoch Done: 1412/-1\n",
      "Number Of Epoch Done: 1413/-1\n",
      "Number Of Epoch Done: 1414/-1\n",
      "Number Of Epoch Done: 1415/-1\n",
      "Number Of Epoch Done: 1416/-1\n",
      "Number Of Epoch Done: 1417/-1\n",
      "Number Of Epoch Done: 1418/-1\n",
      "Number Of Epoch Done: 1419/-1\n",
      "Number Of Epoch Done: 1420/-1\n",
      "Number Of Epoch Done: 1421/-1\n",
      "Number Of Epoch Done: 1422/-1\n",
      "Number Of Epoch Done: 1423/-1\n",
      "Number Of Epoch Done: 1424/-1\n",
      "Number Of Epoch Done: 1425/-1\n",
      "Number Of Epoch Done: 1426/-1\n",
      "Number Of Epoch Done: 1427/-1\n",
      "Number Of Epoch Done: 1428/-1\n",
      "Number Of Epoch Done: 1429/-1\n",
      "Number Of Epoch Done: 1430/-1\n",
      "Number Of Epoch Done: 1431/-1\n",
      "Number Of Epoch Done: 1432/-1\n",
      "Number Of Epoch Done: 1433/-1\n",
      "Number Of Epoch Done: 1434/-1\n",
      "Number Of Epoch Done: 1435/-1\n",
      "Number Of Epoch Done: 1436/-1\n",
      "Number Of Epoch Done: 1437/-1\n",
      "Number Of Epoch Done: 1438/-1\n",
      "Number Of Epoch Done: 1439/-1\n",
      "Number Of Epoch Done: 1440/-1\n",
      "Number Of Epoch Done: 1441/-1\n",
      "Number Of Epoch Done: 1442/-1\n",
      "Number Of Epoch Done: 1443/-1\n",
      "Number Of Epoch Done: 1444/-1\n",
      "Number Of Epoch Done: 1445/-1\n",
      "Number Of Epoch Done: 1446/-1\n",
      "Number Of Epoch Done: 1447/-1\n",
      "Number Of Epoch Done: 1448/-1\n",
      "Number Of Epoch Done: 1449/-1\n",
      "Number Of Epoch Done: 1450/-1\n",
      "Number Of Epoch Done: 1451/-1\n",
      "Number Of Epoch Done: 1452/-1\n",
      "Number Of Epoch Done: 1453/-1\n",
      "Number Of Epoch Done: 1454/-1\n",
      "Number Of Epoch Done: 1455/-1\n",
      "Number Of Epoch Done: 1456/-1\n",
      "Number Of Epoch Done: 1457/-1\n",
      "Number Of Epoch Done: 1458/-1\n",
      "Number Of Epoch Done: 1459/-1\n",
      "Number Of Epoch Done: 1460/-1\n",
      "Number Of Epoch Done: 1461/-1\n",
      "Number Of Epoch Done: 1462/-1\n",
      "Number Of Epoch Done: 1463/-1\n",
      "Number Of Epoch Done: 1464/-1\n",
      "Number Of Epoch Done: 1465/-1\n",
      "Number Of Epoch Done: 1466/-1\n",
      "Number Of Epoch Done: 1467/-1\n",
      "Number Of Epoch Done: 1468/-1\n",
      "Number Of Epoch Done: 1469/-1\n",
      "Number Of Epoch Done: 1470/-1\n",
      "Number Of Epoch Done: 1471/-1\n",
      "Number Of Epoch Done: 1472/-1\n",
      "Number Of Epoch Done: 1473/-1\n",
      "Number Of Epoch Done: 1474/-1\n",
      "Number Of Epoch Done: 1475/-1\n",
      "Number Of Epoch Done: 1476/-1\n",
      "Number Of Epoch Done: 1477/-1\n",
      "Number Of Epoch Done: 1478/-1\n",
      "Number Of Epoch Done: 1479/-1\n",
      "Number Of Epoch Done: 1480/-1\n",
      "Number Of Epoch Done: 1481/-1\n",
      "Number Of Epoch Done: 1482/-1\n",
      "Number Of Epoch Done: 1483/-1\n",
      "Number Of Epoch Done: 1484/-1\n",
      "Number Of Epoch Done: 1485/-1\n",
      "Number Of Epoch Done: 1486/-1\n",
      "Number Of Epoch Done: 1487/-1\n",
      "Number Of Epoch Done: 1488/-1\n",
      "Number Of Epoch Done: 1489/-1\n",
      "Number Of Epoch Done: 1490/-1\n",
      "Number Of Epoch Done: 1491/-1\n",
      "Number Of Epoch Done: 1492/-1\n",
      "Number Of Epoch Done: 1493/-1\n",
      "Number Of Epoch Done: 1494/-1\n",
      "Number Of Epoch Done: 1495/-1\n",
      "Number Of Epoch Done: 1496/-1\n",
      "Number Of Epoch Done: 1497/-1\n",
      "Number Of Epoch Done: 1498/-1\n",
      "Number Of Epoch Done: 1499/-1\n",
      "Number Of Epoch Done: 1500/-1\n",
      "Number Of Epoch Done: 1501/-1\n",
      "Number Of Epoch Done: 1502/-1\n",
      "Number Of Epoch Done: 1503/-1\n",
      "Number Of Epoch Done: 1504/-1\n",
      "Number Of Epoch Done: 1505/-1\n",
      "Number Of Epoch Done: 1506/-1\n",
      "Number Of Epoch Done: 1507/-1\n",
      "Number Of Epoch Done: 1508/-1\n",
      "Number Of Epoch Done: 1509/-1\n",
      "Number Of Epoch Done: 1510/-1\n",
      "Number Of Epoch Done: 1511/-1\n",
      "Number Of Epoch Done: 1512/-1\n",
      "Number Of Epoch Done: 1513/-1\n",
      "Number Of Epoch Done: 1514/-1\n",
      "Number Of Epoch Done: 1515/-1\n",
      "Number Of Epoch Done: 1516/-1\n",
      "Number Of Epoch Done: 1517/-1\n",
      "Number Of Epoch Done: 1518/-1\n",
      "Number Of Epoch Done: 1519/-1\n",
      "Number Of Epoch Done: 1520/-1\n",
      "Number Of Epoch Done: 1521/-1\n",
      "Number Of Epoch Done: 1522/-1\n",
      "Number Of Epoch Done: 1523/-1\n",
      "Number Of Epoch Done: 1524/-1\n",
      "Number Of Epoch Done: 1525/-1\n",
      "Number Of Epoch Done: 1526/-1\n",
      "Number Of Epoch Done: 1527/-1\n",
      "Number Of Epoch Done: 1528/-1\n",
      "Number Of Epoch Done: 1529/-1\n",
      "Number Of Epoch Done: 1530/-1\n",
      "Number Of Epoch Done: 1531/-1\n",
      "Number Of Epoch Done: 1532/-1\n",
      "Number Of Epoch Done: 1533/-1\n",
      "Number Of Epoch Done: 1534/-1\n",
      "Number Of Epoch Done: 1535/-1\n",
      "Number Of Epoch Done: 1536/-1\n",
      "Number Of Epoch Done: 1537/-1\n",
      "Number Of Epoch Done: 1538/-1\n",
      "Number Of Epoch Done: 1539/-1\n",
      "Number Of Epoch Done: 1540/-1\n",
      "Number Of Epoch Done: 1541/-1\n",
      "Number Of Epoch Done: 1542/-1\n",
      "Number Of Epoch Done: 1543/-1\n",
      "Number Of Epoch Done: 1544/-1\n",
      "Number Of Epoch Done: 1545/-1\n",
      "Number Of Epoch Done: 1546/-1\n",
      "Number Of Epoch Done: 1547/-1\n",
      "Number Of Epoch Done: 1548/-1\n",
      "Number Of Epoch Done: 1549/-1\n",
      "Number Of Epoch Done: 1550/-1\n",
      "Number Of Epoch Done: 1551/-1\n",
      "Number Of Epoch Done: 1552/-1\n",
      "Number Of Epoch Done: 1553/-1\n",
      "Number Of Epoch Done: 1554/-1\n",
      "Number Of Epoch Done: 1555/-1\n",
      "Number Of Epoch Done: 1556/-1\n",
      "Number Of Epoch Done: 1557/-1\n",
      "Number Of Epoch Done: 1558/-1\n",
      "Number Of Epoch Done: 1559/-1\n",
      "Number Of Epoch Done: 1560/-1\n",
      "Number Of Epoch Done: 1561/-1\n",
      "Number Of Epoch Done: 1562/-1\n",
      "Number Of Epoch Done: 1563/-1\n",
      "Number Of Epoch Done: 1564/-1\n",
      "Number Of Epoch Done: 1565/-1\n",
      "Number Of Epoch Done: 1566/-1\n",
      "Number Of Epoch Done: 1567/-1\n",
      "Number Of Epoch Done: 1568/-1\n",
      "Number Of Epoch Done: 1569/-1\n",
      "Number Of Epoch Done: 1570/-1\n",
      "Number Of Epoch Done: 1571/-1\n",
      "Number Of Epoch Done: 1572/-1\n",
      "Number Of Epoch Done: 1573/-1\n",
      "Number Of Epoch Done: 1574/-1\n",
      "Number Of Epoch Done: 1575/-1\n",
      "Number Of Epoch Done: 1576/-1\n",
      "Number Of Epoch Done: 1577/-1\n",
      "Number Of Epoch Done: 1578/-1\n",
      "Number Of Epoch Done: 1579/-1\n",
      "Number Of Epoch Done: 1580/-1\n",
      "Number Of Epoch Done: 1581/-1\n",
      "Number Of Epoch Done: 1582/-1\n",
      "Number Of Epoch Done: 1583/-1\n",
      "Number Of Epoch Done: 1584/-1\n",
      "Number Of Epoch Done: 1585/-1\n",
      "Number Of Epoch Done: 1586/-1\n",
      "Number Of Epoch Done: 1587/-1\n",
      "Number Of Epoch Done: 1588/-1\n",
      "Number Of Epoch Done: 1589/-1\n",
      "Number Of Epoch Done: 1590/-1\n",
      "Number Of Epoch Done: 1591/-1\n",
      "Number Of Epoch Done: 1592/-1\n",
      "Number Of Epoch Done: 1593/-1\n",
      "Number Of Epoch Done: 1594/-1\n",
      "Number Of Epoch Done: 1595/-1\n",
      "Number Of Epoch Done: 1596/-1\n",
      "Number Of Epoch Done: 1597/-1\n",
      "Number Of Epoch Done: 1598/-1\n",
      "Number Of Epoch Done: 1599/-1\n",
      "Number Of Epoch Done: 1600/-1\n",
      "Number Of Epoch Done: 1601/-1\n",
      "Number Of Epoch Done: 1602/-1\n",
      "Number Of Epoch Done: 1603/-1\n",
      "Number Of Epoch Done: 1604/-1\n",
      "Number Of Epoch Done: 1605/-1\n",
      "Number Of Epoch Done: 1606/-1\n",
      "Number Of Epoch Done: 1607/-1\n",
      "Number Of Epoch Done: 1608/-1\n",
      "Number Of Epoch Done: 1609/-1\n",
      "Number Of Epoch Done: 1610/-1\n",
      "Number Of Epoch Done: 1611/-1\n",
      "Number Of Epoch Done: 1612/-1\n",
      "Number Of Epoch Done: 1613/-1\n",
      "Number Of Epoch Done: 1614/-1\n",
      "Number Of Epoch Done: 1615/-1\n",
      "Number Of Epoch Done: 1616/-1\n",
      "Number Of Epoch Done: 1617/-1\n",
      "Number Of Epoch Done: 1618/-1\n",
      "Number Of Epoch Done: 1619/-1\n",
      "Number Of Epoch Done: 1620/-1\n",
      "Number Of Epoch Done: 1621/-1\n",
      "Number Of Epoch Done: 1622/-1\n",
      "Number Of Epoch Done: 1623/-1\n",
      "Number Of Epoch Done: 1624/-1\n",
      "Number Of Epoch Done: 1625/-1\n",
      "Number Of Epoch Done: 1626/-1\n",
      "Number Of Epoch Done: 1627/-1\n",
      "Number Of Epoch Done: 1628/-1\n",
      "Number Of Epoch Done: 1629/-1\n",
      "Number Of Epoch Done: 1630/-1\n",
      "Number Of Epoch Done: 1631/-1\n",
      "Number Of Epoch Done: 1632/-1\n",
      "Number Of Epoch Done: 1633/-1\n",
      "Number Of Epoch Done: 1634/-1\n",
      "Number Of Epoch Done: 1635/-1\n",
      "Number Of Epoch Done: 1636/-1\n",
      "Number Of Epoch Done: 1637/-1\n",
      "Number Of Epoch Done: 1638/-1\n",
      "Number Of Epoch Done: 1639/-1\n",
      "Number Of Epoch Done: 1640/-1\n",
      "Number Of Epoch Done: 1641/-1\n",
      "Number Of Epoch Done: 1642/-1\n",
      "Number Of Epoch Done: 1643/-1\n",
      "Number Of Epoch Done: 1644/-1\n",
      "Number Of Epoch Done: 1645/-1\n",
      "Number Of Epoch Done: 1646/-1\n",
      "Number Of Epoch Done: 1647/-1\n",
      "Number Of Epoch Done: 1648/-1\n",
      "Number Of Epoch Done: 1649/-1\n",
      "Number Of Epoch Done: 1650/-1\n",
      "Number Of Epoch Done: 1651/-1\n",
      "Number Of Epoch Done: 1652/-1\n",
      "Number Of Epoch Done: 1653/-1\n",
      "Number Of Epoch Done: 1654/-1\n",
      "Number Of Epoch Done: 1655/-1\n",
      "Number Of Epoch Done: 1656/-1\n",
      "Number Of Epoch Done: 1657/-1\n",
      "Number Of Epoch Done: 1658/-1\n",
      "Number Of Epoch Done: 1659/-1\n",
      "Number Of Epoch Done: 1660/-1\n",
      "Number Of Epoch Done: 1661/-1\n",
      "Number Of Epoch Done: 1662/-1\n",
      "Number Of Epoch Done: 1663/-1\n",
      "Number Of Epoch Done: 1664/-1\n",
      "Number Of Epoch Done: 1665/-1\n",
      "Number Of Epoch Done: 1666/-1\n",
      "Number Of Epoch Done: 1667/-1\n",
      "Number Of Epoch Done: 1668/-1\n",
      "Number Of Epoch Done: 1669/-1\n",
      "Number Of Epoch Done: 1670/-1\n",
      "Number Of Epoch Done: 1671/-1\n",
      "Number Of Epoch Done: 1672/-1\n",
      "Number Of Epoch Done: 1673/-1\n",
      "Number Of Epoch Done: 1674/-1\n",
      "Number Of Epoch Done: 1675/-1\n",
      "Number Of Epoch Done: 1676/-1\n",
      "Number Of Epoch Done: 1677/-1\n",
      "Number Of Epoch Done: 1678/-1\n",
      "Number Of Epoch Done: 1679/-1\n",
      "Number Of Epoch Done: 1680/-1\n",
      "Number Of Epoch Done: 1681/-1\n",
      "Number Of Epoch Done: 1682/-1\n",
      "Number Of Epoch Done: 1683/-1\n",
      "Number Of Epoch Done: 1684/-1\n",
      "Number Of Epoch Done: 1685/-1\n",
      "Number Of Epoch Done: 1686/-1\n",
      "Number Of Epoch Done: 1687/-1\n",
      "Number Of Epoch Done: 1688/-1\n",
      "Number Of Epoch Done: 1689/-1\n",
      "Number Of Epoch Done: 1690/-1\n",
      "Number Of Epoch Done: 1691/-1\n",
      "Number Of Epoch Done: 1692/-1\n",
      "Number Of Epoch Done: 1693/-1\n",
      "Number Of Epoch Done: 1694/-1\n",
      "Number Of Epoch Done: 1695/-1\n",
      "Number Of Epoch Done: 1696/-1\n",
      "Number Of Epoch Done: 1697/-1\n",
      "Number Of Epoch Done: 1698/-1\n",
      "Number Of Epoch Done: 1699/-1\n",
      "Number Of Epoch Done: 1700/-1\n",
      "Number Of Epoch Done: 1701/-1\n",
      "Number Of Epoch Done: 1702/-1\n",
      "Number Of Epoch Done: 1703/-1\n",
      "Number Of Epoch Done: 1704/-1\n",
      "Number Of Epoch Done: 1705/-1\n",
      "Number Of Epoch Done: 1706/-1\n",
      "Number Of Epoch Done: 1707/-1\n",
      "Number Of Epoch Done: 1708/-1\n",
      "Number Of Epoch Done: 1709/-1\n",
      "Number Of Epoch Done: 1710/-1\n",
      "Number Of Epoch Done: 1711/-1\n",
      "Number Of Epoch Done: 1712/-1\n",
      "Number Of Epoch Done: 1713/-1\n",
      "Number Of Epoch Done: 1714/-1\n",
      "Number Of Epoch Done: 1715/-1\n",
      "Number Of Epoch Done: 1716/-1\n",
      "Number Of Epoch Done: 1717/-1\n",
      "Number Of Epoch Done: 1718/-1\n",
      "Number Of Epoch Done: 1719/-1\n",
      "Number Of Epoch Done: 1720/-1\n",
      "Number Of Epoch Done: 1721/-1\n",
      "Number Of Epoch Done: 1722/-1\n",
      "Number Of Epoch Done: 1723/-1\n",
      "Number Of Epoch Done: 1724/-1\n",
      "Number Of Epoch Done: 1725/-1\n",
      "Number Of Epoch Done: 1726/-1\n",
      "Number Of Epoch Done: 1727/-1\n",
      "Number Of Epoch Done: 1728/-1\n",
      "Number Of Epoch Done: 1729/-1\n",
      "Number Of Epoch Done: 1730/-1\n",
      "Number Of Epoch Done: 1731/-1\n",
      "Number Of Epoch Done: 1732/-1\n",
      "Number Of Epoch Done: 1733/-1\n",
      "Number Of Epoch Done: 1734/-1\n",
      "Number Of Epoch Done: 1735/-1\n",
      "Number Of Epoch Done: 1736/-1\n",
      "Number Of Epoch Done: 1737/-1\n",
      "Number Of Epoch Done: 1738/-1\n",
      "Number Of Epoch Done: 1739/-1\n",
      "Number Of Epoch Done: 1740/-1\n",
      "Number Of Epoch Done: 1741/-1\n",
      "Number Of Epoch Done: 1742/-1\n",
      "Number Of Epoch Done: 1743/-1\n",
      "Number Of Epoch Done: 1744/-1\n",
      "Number Of Epoch Done: 1745/-1\n",
      "Number Of Epoch Done: 1746/-1\n",
      "Number Of Epoch Done: 1747/-1\n",
      "Number Of Epoch Done: 1748/-1\n",
      "Number Of Epoch Done: 1749/-1\n",
      "Number Of Epoch Done: 1750/-1\n",
      "Number Of Epoch Done: 1751/-1\n",
      "Number Of Epoch Done: 1752/-1\n",
      "Number Of Epoch Done: 1753/-1\n",
      "Number Of Epoch Done: 1754/-1\n",
      "Number Of Epoch Done: 1755/-1\n",
      "Number Of Epoch Done: 1756/-1\n",
      "Number Of Epoch Done: 1757/-1\n",
      "Number Of Epoch Done: 1758/-1\n",
      "Number Of Epoch Done: 1759/-1\n",
      "Number Of Epoch Done: 1760/-1\n",
      "Number Of Epoch Done: 1761/-1\n",
      "Number Of Epoch Done: 1762/-1\n",
      "Number Of Epoch Done: 1763/-1\n",
      "Number Of Epoch Done: 1764/-1\n",
      "Number Of Epoch Done: 1765/-1\n",
      "Number Of Epoch Done: 1766/-1\n",
      "Number Of Epoch Done: 1767/-1\n",
      "Number Of Epoch Done: 1768/-1\n",
      "Number Of Epoch Done: 1769/-1\n",
      "Number Of Epoch Done: 1770/-1\n",
      "Number Of Epoch Done: 1771/-1\n",
      "Number Of Epoch Done: 1772/-1\n",
      "Number Of Epoch Done: 1773/-1\n",
      "Number Of Epoch Done: 1774/-1\n",
      "Number Of Epoch Done: 1775/-1\n",
      "Number Of Epoch Done: 1776/-1\n",
      "Number Of Epoch Done: 1777/-1\n",
      "Number Of Epoch Done: 1778/-1\n",
      "Number Of Epoch Done: 1779/-1\n",
      "Number Of Epoch Done: 1780/-1\n",
      "Number Of Epoch Done: 1781/-1\n",
      "Number Of Epoch Done: 1782/-1\n",
      "Number Of Epoch Done: 1783/-1\n",
      "Number Of Epoch Done: 1784/-1\n",
      "Number Of Epoch Done: 1785/-1\n",
      "Number Of Epoch Done: 1786/-1\n",
      "Number Of Epoch Done: 1787/-1\n",
      "Number Of Epoch Done: 1788/-1\n",
      "Number Of Epoch Done: 1789/-1\n",
      "Number Of Epoch Done: 1790/-1\n",
      "Number Of Epoch Done: 1791/-1\n",
      "Number Of Epoch Done: 1792/-1\n",
      "Number Of Epoch Done: 1793/-1\n",
      "Number Of Epoch Done: 1794/-1\n",
      "Number Of Epoch Done: 1795/-1\n",
      "Number Of Epoch Done: 1796/-1\n",
      "Number Of Epoch Done: 1797/-1\n",
      "Number Of Epoch Done: 1798/-1\n",
      "Number Of Epoch Done: 1799/-1\n",
      "Number Of Epoch Done: 1800/-1\n",
      "Number Of Epoch Done: 1801/-1\n",
      "Number Of Epoch Done: 1802/-1\n",
      "Number Of Epoch Done: 1803/-1\n",
      "Number Of Epoch Done: 1804/-1\n",
      "Number Of Epoch Done: 1805/-1\n",
      "Number Of Epoch Done: 1806/-1\n",
      "Number Of Epoch Done: 1807/-1\n",
      "Number Of Epoch Done: 1808/-1\n",
      "Number Of Epoch Done: 1809/-1\n",
      "Number Of Epoch Done: 1810/-1\n",
      "Number Of Epoch Done: 1811/-1\n",
      "Number Of Epoch Done: 1812/-1\n",
      "Number Of Epoch Done: 1813/-1\n",
      "Number Of Epoch Done: 1814/-1\n",
      "Number Of Epoch Done: 1815/-1\n",
      "Number Of Epoch Done: 1816/-1\n",
      "Number Of Epoch Done: 1817/-1\n",
      "Number Of Epoch Done: 1818/-1\n",
      "Number Of Epoch Done: 1819/-1\n",
      "Number Of Epoch Done: 1820/-1\n",
      "Number Of Epoch Done: 1821/-1\n",
      "Number Of Epoch Done: 1822/-1\n",
      "Number Of Epoch Done: 1823/-1\n",
      "Number Of Epoch Done: 1824/-1\n",
      "Number Of Epoch Done: 1825/-1\n",
      "Number Of Epoch Done: 1826/-1\n",
      "Number Of Epoch Done: 1827/-1\n",
      "Number Of Epoch Done: 1828/-1\n",
      "Number Of Epoch Done: 1829/-1\n",
      "Number Of Epoch Done: 1830/-1\n",
      "Number Of Epoch Done: 1831/-1\n",
      "Number Of Epoch Done: 1832/-1\n",
      "Number Of Epoch Done: 1833/-1\n",
      "Number Of Epoch Done: 1834/-1\n",
      "Number Of Epoch Done: 1835/-1\n",
      "Number Of Epoch Done: 1836/-1\n",
      "Number Of Epoch Done: 1837/-1\n",
      "Number Of Epoch Done: 1838/-1\n",
      "Number Of Epoch Done: 1839/-1\n",
      "Number Of Epoch Done: 1840/-1\n",
      "Number Of Epoch Done: 1841/-1\n",
      "Number Of Epoch Done: 1842/-1\n",
      "Number Of Epoch Done: 1843/-1\n",
      "Number Of Epoch Done: 1844/-1\n",
      "Number Of Epoch Done: 1845/-1\n",
      "Number Of Epoch Done: 1846/-1\n",
      "Number Of Epoch Done: 1847/-1\n",
      "Number Of Epoch Done: 1848/-1\n",
      "Number Of Epoch Done: 1849/-1\n",
      "Number Of Epoch Done: 1850/-1\n",
      "Number Of Epoch Done: 1851/-1\n",
      "Number Of Epoch Done: 1852/-1\n",
      "Number Of Epoch Done: 1853/-1\n",
      "Number Of Epoch Done: 1854/-1\n",
      "Number Of Epoch Done: 1855/-1\n",
      "Number Of Epoch Done: 1856/-1\n",
      "Number Of Epoch Done: 1857/-1\n",
      "Number Of Epoch Done: 1858/-1\n",
      "Number Of Epoch Done: 1859/-1\n",
      "Number Of Epoch Done: 1860/-1\n",
      "Number Of Epoch Done: 1861/-1\n",
      "Number Of Epoch Done: 1862/-1\n",
      "Number Of Epoch Done: 1863/-1\n",
      "Number Of Epoch Done: 1864/-1\n",
      "Number Of Epoch Done: 1865/-1\n",
      "Number Of Epoch Done: 1866/-1\n",
      "Number Of Epoch Done: 1867/-1\n",
      "Number Of Epoch Done: 1868/-1\n",
      "Number Of Epoch Done: 1869/-1\n",
      "Number Of Epoch Done: 1870/-1\n",
      "Number Of Epoch Done: 1871/-1\n",
      "Number Of Epoch Done: 1872/-1\n",
      "Number Of Epoch Done: 1873/-1\n",
      "Number Of Epoch Done: 1874/-1\n",
      "Number Of Epoch Done: 1875/-1\n",
      "Number Of Epoch Done: 1876/-1\n",
      "Number Of Epoch Done: 1877/-1\n",
      "Number Of Epoch Done: 1878/-1\n",
      "Number Of Epoch Done: 1879/-1\n",
      "Number Of Epoch Done: 1880/-1\n",
      "Number Of Epoch Done: 1881/-1\n",
      "Number Of Epoch Done: 1882/-1\n",
      "Number Of Epoch Done: 1883/-1\n",
      "Number Of Epoch Done: 1884/-1\n",
      "Number Of Epoch Done: 1885/-1\n",
      "Number Of Epoch Done: 1886/-1\n",
      "Number Of Epoch Done: 1887/-1\n",
      "Number Of Epoch Done: 1888/-1\n",
      "Number Of Epoch Done: 1889/-1\n",
      "Number Of Epoch Done: 1890/-1\n",
      "Number Of Epoch Done: 1891/-1\n",
      "Number Of Epoch Done: 1892/-1\n",
      "Number Of Epoch Done: 1893/-1\n",
      "Number Of Epoch Done: 1894/-1\n",
      "Number Of Epoch Done: 1895/-1\n",
      "Number Of Epoch Done: 1896/-1\n",
      "Number Of Epoch Done: 1897/-1\n",
      "Number Of Epoch Done: 1898/-1\n",
      "Number Of Epoch Done: 1899/-1\n",
      "Number Of Epoch Done: 1900/-1\n",
      "Number Of Epoch Done: 1901/-1\n",
      "Number Of Epoch Done: 1902/-1\n",
      "Number Of Epoch Done: 1903/-1\n",
      "Number Of Epoch Done: 1904/-1\n",
      "Number Of Epoch Done: 1905/-1\n",
      "Number Of Epoch Done: 1906/-1\n",
      "Number Of Epoch Done: 1907/-1\n",
      "Number Of Epoch Done: 1908/-1\n",
      "Number Of Epoch Done: 1909/-1\n",
      "Number Of Epoch Done: 1910/-1\n",
      "Number Of Epoch Done: 1911/-1\n",
      "Number Of Epoch Done: 1912/-1\n",
      "Number Of Epoch Done: 1913/-1\n",
      "Number Of Epoch Done: 1914/-1\n",
      "Number Of Epoch Done: 1915/-1\n",
      "Number Of Epoch Done: 1916/-1\n",
      "Number Of Epoch Done: 1917/-1\n",
      "Number Of Epoch Done: 1918/-1\n",
      "Number Of Epoch Done: 1919/-1\n",
      "Number Of Epoch Done: 1920/-1\n",
      "Number Of Epoch Done: 1921/-1\n",
      "Number Of Epoch Done: 1922/-1\n",
      "Number Of Epoch Done: 1923/-1\n",
      "Number Of Epoch Done: 1924/-1\n",
      "Number Of Epoch Done: 1925/-1\n",
      "Number Of Epoch Done: 1926/-1\n",
      "Number Of Epoch Done: 1927/-1\n",
      "Number Of Epoch Done: 1928/-1\n",
      "Number Of Epoch Done: 1929/-1\n",
      "Number Of Epoch Done: 1930/-1\n",
      "Number Of Epoch Done: 1931/-1\n",
      "Number Of Epoch Done: 1932/-1\n",
      "Number Of Epoch Done: 1933/-1\n",
      "Number Of Epoch Done: 1934/-1\n",
      "Number Of Epoch Done: 1935/-1\n",
      "Number Of Epoch Done: 1936/-1\n",
      "Number Of Epoch Done: 1937/-1\n",
      "Number Of Epoch Done: 1938/-1\n",
      "Number Of Epoch Done: 1939/-1\n",
      "Number Of Epoch Done: 1940/-1\n",
      "Number Of Epoch Done: 1941/-1\n",
      "Number Of Epoch Done: 1942/-1\n",
      "Number Of Epoch Done: 1943/-1\n",
      "Number Of Epoch Done: 1944/-1\n",
      "Number Of Epoch Done: 1945/-1\n",
      "Number Of Epoch Done: 1946/-1\n",
      "Number Of Epoch Done: 1947/-1\n",
      "Number Of Epoch Done: 1948/-1\n",
      "Number Of Epoch Done: 1949/-1\n",
      "Number Of Epoch Done: 1950/-1\n",
      "Number Of Epoch Done: 1951/-1\n",
      "Number Of Epoch Done: 1952/-1\n",
      "Number Of Epoch Done: 1953/-1\n",
      "Number Of Epoch Done: 1954/-1\n",
      "Number Of Epoch Done: 1955/-1\n",
      "Number Of Epoch Done: 1956/-1\n",
      "Number Of Epoch Done: 1957/-1\n",
      "Number Of Epoch Done: 1958/-1\n",
      "Number Of Epoch Done: 1959/-1\n",
      "Number Of Epoch Done: 1960/-1\n",
      "Number Of Epoch Done: 1961/-1\n",
      "Number Of Epoch Done: 1962/-1\n",
      "Number Of Epoch Done: 1963/-1\n",
      "Number Of Epoch Done: 1964/-1\n",
      "Number Of Epoch Done: 1965/-1\n",
      "Number Of Epoch Done: 1966/-1\n",
      "Number Of Epoch Done: 1967/-1\n",
      "Number Of Epoch Done: 1968/-1\n",
      "Number Of Epoch Done: 1969/-1\n",
      "Number Of Epoch Done: 1970/-1\n",
      "Number Of Epoch Done: 1971/-1\n",
      "Number Of Epoch Done: 1972/-1\n",
      "Number Of Epoch Done: 1973/-1\n",
      "Number Of Epoch Done: 1974/-1\n",
      "Number Of Epoch Done: 1975/-1\n",
      "Number Of Epoch Done: 1976/-1\n",
      "Number Of Epoch Done: 1977/-1\n",
      "Number Of Epoch Done: 1978/-1\n",
      "Number Of Epoch Done: 1979/-1\n",
      "Number Of Epoch Done: 1980/-1\n",
      "Number Of Epoch Done: 1981/-1\n",
      "Number Of Epoch Done: 1982/-1\n",
      "Number Of Epoch Done: 1983/-1\n",
      "Number Of Epoch Done: 1984/-1\n",
      "Number Of Epoch Done: 1985/-1\n",
      "Number Of Epoch Done: 1986/-1\n",
      "Number Of Epoch Done: 1987/-1\n",
      "Number Of Epoch Done: 1988/-1\n",
      "Number Of Epoch Done: 1989/-1\n",
      "Number Of Epoch Done: 1990/-1\n",
      "Number Of Epoch Done: 1991/-1\n",
      "Number Of Epoch Done: 1992/-1\n",
      "Number Of Epoch Done: 1993/-1\n",
      "Number Of Epoch Done: 1994/-1\n",
      "Number Of Epoch Done: 1995/-1\n",
      "Number Of Epoch Done: 1996/-1\n",
      "Number Of Epoch Done: 1997/-1\n",
      "Number Of Epoch Done: 1998/-1\n",
      "Number Of Epoch Done: 1999/-1\n",
      "Number Of Epoch Done: 2000/-1\n",
      "Number Of Epoch Done: 2001/-1\n",
      "Number Of Epoch Done: 2002/-1\n",
      "Number Of Epoch Done: 2003/-1\n",
      "Number Of Epoch Done: 2004/-1\n",
      "Number Of Epoch Done: 2005/-1\n",
      "Number Of Epoch Done: 2006/-1\n",
      "Number Of Epoch Done: 2007/-1\n",
      "Number Of Epoch Done: 2008/-1\n",
      "Number Of Epoch Done: 2009/-1\n",
      "Number Of Epoch Done: 2010/-1\n",
      "Number Of Epoch Done: 2011/-1\n",
      "Number Of Epoch Done: 2012/-1\n",
      "Number Of Epoch Done: 2013/-1\n",
      "Number Of Epoch Done: 2014/-1\n",
      "Number Of Epoch Done: 2015/-1\n",
      "Number Of Epoch Done: 2016/-1\n",
      "Number Of Epoch Done: 2017/-1\n",
      "Number Of Epoch Done: 2018/-1\n",
      "Number Of Epoch Done: 2019/-1\n",
      "Number Of Epoch Done: 2020/-1\n",
      "Number Of Epoch Done: 2021/-1\n",
      "Number Of Epoch Done: 2022/-1\n",
      "Number Of Epoch Done: 2023/-1\n",
      "Number Of Epoch Done: 2024/-1\n",
      "Number Of Epoch Done: 2025/-1\n",
      "Number Of Epoch Done: 2026/-1\n",
      "Number Of Epoch Done: 2027/-1\n",
      "Number Of Epoch Done: 2028/-1\n",
      "Number Of Epoch Done: 2029/-1\n",
      "Number Of Epoch Done: 2030/-1\n",
      "Number Of Epoch Done: 2031/-1\n",
      "Number Of Epoch Done: 2032/-1\n",
      "Number Of Epoch Done: 2033/-1\n",
      "Number Of Epoch Done: 2034/-1\n",
      "Number Of Epoch Done: 2035/-1\n",
      "Number Of Epoch Done: 2036/-1\n",
      "Number Of Epoch Done: 2037/-1\n",
      "Number Of Epoch Done: 2038/-1\n",
      "Number Of Epoch Done: 2039/-1\n",
      "Number Of Epoch Done: 2040/-1\n",
      "Number Of Epoch Done: 2041/-1\n",
      "Number Of Epoch Done: 2042/-1\n",
      "Number Of Epoch Done: 2043/-1\n",
      "Number Of Epoch Done: 2044/-1\n",
      "Number Of Epoch Done: 2045/-1\n",
      "Number Of Epoch Done: 2046/-1\n",
      "Number Of Epoch Done: 2047/-1\n",
      "Number Of Epoch Done: 2048/-1\n",
      "Number Of Epoch Done: 2049/-1\n",
      "Number Of Epoch Done: 2050/-1\n",
      "Number Of Epoch Done: 2051/-1\n",
      "Number Of Epoch Done: 2052/-1\n",
      "Number Of Epoch Done: 2053/-1\n",
      "Number Of Epoch Done: 2054/-1\n",
      "Number Of Epoch Done: 2055/-1\n",
      "Number Of Epoch Done: 2056/-1\n",
      "Number Of Epoch Done: 2057/-1\n",
      "Number Of Epoch Done: 2058/-1\n",
      "Number Of Epoch Done: 2059/-1\n",
      "Number Of Epoch Done: 2060/-1\n",
      "Number Of Epoch Done: 2061/-1\n",
      "Number Of Epoch Done: 2062/-1\n",
      "Number Of Epoch Done: 2063/-1\n",
      "Number Of Epoch Done: 2064/-1\n",
      "Number Of Epoch Done: 2065/-1\n",
      "Number Of Epoch Done: 2066/-1\n",
      "Number Of Epoch Done: 2067/-1\n",
      "Number Of Epoch Done: 2068/-1\n",
      "Number Of Epoch Done: 2069/-1\n",
      "Number Of Epoch Done: 2070/-1\n",
      "Number Of Epoch Done: 2071/-1\n",
      "Number Of Epoch Done: 2072/-1\n",
      "Number Of Epoch Done: 2073/-1\n",
      "Number Of Epoch Done: 2074/-1\n",
      "Number Of Epoch Done: 2075/-1\n",
      "Number Of Epoch Done: 2076/-1\n",
      "Number Of Epoch Done: 2077/-1\n",
      "Number Of Epoch Done: 2078/-1\n",
      "Number Of Epoch Done: 2079/-1\n",
      "Number Of Epoch Done: 2080/-1\n",
      "Number Of Epoch Done: 2081/-1\n",
      "Number Of Epoch Done: 2082/-1\n",
      "Number Of Epoch Done: 2083/-1\n",
      "Number Of Epoch Done: 2084/-1\n",
      "Number Of Epoch Done: 2085/-1\n",
      "Number Of Epoch Done: 2086/-1\n",
      "Number Of Epoch Done: 2087/-1\n",
      "Number Of Epoch Done: 2088/-1\n",
      "Number Of Epoch Done: 2089/-1\n",
      "Number Of Epoch Done: 2090/-1\n",
      "Number Of Epoch Done: 2091/-1\n",
      "Number Of Epoch Done: 2092/-1\n",
      "Number Of Epoch Done: 2093/-1\n",
      "Number Of Epoch Done: 2094/-1\n",
      "Number Of Epoch Done: 2095/-1\n",
      "Number Of Epoch Done: 2096/-1\n",
      "Number Of Epoch Done: 2097/-1\n",
      "Number Of Epoch Done: 2098/-1\n",
      "Number Of Epoch Done: 2099/-1\n",
      "Number Of Epoch Done: 2100/-1\n",
      "Number Of Epoch Done: 2101/-1\n",
      "Number Of Epoch Done: 2102/-1\n",
      "Number Of Epoch Done: 2103/-1\n",
      "Number Of Epoch Done: 2104/-1\n",
      "Number Of Epoch Done: 2105/-1\n",
      "Number Of Epoch Done: 2106/-1\n",
      "Number Of Epoch Done: 2107/-1\n",
      "Number Of Epoch Done: 2108/-1\n",
      "Number Of Epoch Done: 2109/-1\n",
      "Number Of Epoch Done: 2110/-1\n",
      "Number Of Epoch Done: 2111/-1\n",
      "Number Of Epoch Done: 2112/-1\n",
      "Number Of Epoch Done: 2113/-1\n",
      "Number Of Epoch Done: 2114/-1\n",
      "Number Of Epoch Done: 2115/-1\n",
      "Number Of Epoch Done: 2116/-1\n",
      "Number Of Epoch Done: 2117/-1\n",
      "Number Of Epoch Done: 2118/-1\n",
      "Number Of Epoch Done: 2119/-1\n",
      "Number Of Epoch Done: 2120/-1\n",
      "Number Of Epoch Done: 2121/-1\n",
      "Number Of Epoch Done: 2122/-1\n",
      "Number Of Epoch Done: 2123/-1\n",
      "Number Of Epoch Done: 2124/-1\n",
      "Number Of Epoch Done: 2125/-1\n",
      "Number Of Epoch Done: 2126/-1\n",
      "Number Of Epoch Done: 2127/-1\n",
      "Number Of Epoch Done: 2128/-1\n",
      "Number Of Epoch Done: 2129/-1\n",
      "Number Of Epoch Done: 2130/-1\n",
      "Number Of Epoch Done: 2131/-1\n",
      "Number Of Epoch Done: 2132/-1\n",
      "Number Of Epoch Done: 2133/-1\n",
      "Number Of Epoch Done: 2134/-1\n",
      "Number Of Epoch Done: 2135/-1\n",
      "Number Of Epoch Done: 2136/-1\n",
      "Number Of Epoch Done: 2137/-1\n",
      "Number Of Epoch Done: 2138/-1\n",
      "Number Of Epoch Done: 2139/-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/tkinter/__init__.py\", line 1971, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/tkinter/__init__.py\", line 865, in callit\n",
      "    func(*args)\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/backends/_backend_tk.py\", line 271, in idle_draw\n",
      "    self.draw()\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/backends/backend_tkagg.py\", line 10, in draw\n",
      "    super().draw()\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py\", line 387, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/artist.py\", line 95, in draw_wrapper\n",
      "    result = draw(artist, renderer, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/figure.py\", line 3162, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/axes/_base.py\", line 3137, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/image.py\", line 653, in draw\n",
      "    im, l, b, trans = self.make_image(\n",
      "                      ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/image.py\", line 952, in make_image\n",
      "    return self._make_image(self._A, bbox, transformed_bbox, clip,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/image.py\", line 504, in _make_image\n",
      "    A_resampled = _resample(self, A_scaled, out_shape, t)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/image.py\", line 208, in _resample\n",
      "    _image.resample(data, out, transform,\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Epoch Done: 2140/-1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 57\u001b[0m\n\u001b[1;32m     52\u001b[0m trans_img\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[1;32m     56\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 57\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreconstructed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mauto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m, in \u001b[0;36mCoverArtsDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprepareTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m, in \u001b[0;36mprepareTensor\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepareTensor\u001b[39m(path):\n\u001b[1;32m      2\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(path)\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m99\u001b[39m, \u001b[38;5;241m99\u001b[39m))\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     img\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torchvision/transforms/functional.py:176\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    174\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "raw_img = fig.add_axes([0, 0.5, 0.5 - 0.02, 0.5 - 0.02])\n",
    "trans_img = fig.add_axes([0.5, 0.5, 0.5 - 0.02, 0.5 - 0.02])\n",
    "\n",
    "loss_ax = fig.add_axes([0, 0, 1 - 0.02, 0.5 - 0.02])\n",
    "\n",
    "raw_img.axis(\"off\")\n",
    "trans_img.axis(\"off\")\n",
    "loss_ax.axis(\"off\")\n",
    "\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "print(f\"Using Device: {device}\")\n",
    "auto = ConvAutoencoder().to(device)\n",
    "epoch = 0\n",
    "try:\n",
    "    epoch, model_dict = helper_fetch_localmodel()\n",
    "    auto.load_state_dict(model_dict)\n",
    "    print(f\"[INFO]: Model Loaded with {epoch=}\")\n",
    "except Exception as e:\n",
    "    print(\"[ERROR]: Cant Load Saved Model\", e)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(auto.parameters(), lr=0.001)\n",
    "NUM_EPOCHS = -1\n",
    "BATCH_SIZE = 40\n",
    "\n",
    "if NUM_EPOCHS > 0: loss_ax.set_xlim(left=0, right=NUM_EPOCHS)\n",
    "dataset = CoverArtsDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "try:\n",
    "    while epoch != NUM_EPOCHS:\n",
    "        \n",
    "        sample_path = random.choice(image_paths)\n",
    "        sample_data = prepareTensor(sample_path).unsqueeze(1)\n",
    "        sample = auto(sample_data.to(device))\n",
    "\n",
    "        \n",
    "        img = toimg(sample.to(\"cpu\"))\n",
    "\n",
    "        raw_img.imshow(np.uint8((sample_data.view(99, 99) * 255).detach().numpy()))\n",
    "        trans_img.imshow(img)\n",
    "\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        for data in dataloader:\n",
    "            reconstructed = auto(data.to(device)).to(device)\n",
    "            original = data.to(device)\n",
    "            loss = criterion(reconstructed, original).to(device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        loss_ax.plot(epoch, loss.to(\"cpu\").item(), \"ro--\")\n",
    "        fig.show()\n",
    "        fig.canvas.flush_events()\n",
    "        epoch += 1\n",
    "        \n",
    "        \n",
    "        print(f\"Number Of Epoch Done: {epoch}/{NUM_EPOCHS}\")\n",
    "except Exception as e:\n",
    "    print(\"[ERROR]: Training is intrupted!!\", e)\n",
    "finally:\n",
    "    torch.save(auto.state_dict(), f\"autoencoder_{epoch}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1433eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "REPRESENTATION_DIM = 100\n",
    "\n",
    "\n",
    "samples = []\n",
    "for path in image_paths:\n",
    "    im = Image.open(path)\n",
    "    data = np.uint8(im).flatten()\n",
    "    samples += [ data ]\n",
    "    im.close()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "\n",
    "samples = scaler.fit_transform(samples)\n",
    "pca = PCA(n_components=REPRESENTATION_DIM).fit(samples)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02ab1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18742653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    return np.float32(Image.open(path)) / 255\n",
    "\n",
    "def encode_image(path):\n",
    "    im = read_image(path)\n",
    "    data = im.flatten().reshape(1, -1)\n",
    "    data = scaler.transform(data)\n",
    "    return im, pca.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb37bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda, Device used\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(2, (10, 10)),\n",
    "            nn.ConvTranspose2d(in_channels=1, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.UpsamplingNearest2d(None, (3, 3)),\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.UpsamplingNearest2d(None, (3, 3)),\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.UpsamplingNearest2d(None, (3, 3)),\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.UpsamplingNearest2d((300, 300)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "    \n",
    "def prepareTensor(encoded_image):\n",
    "    return torch.tensor(encoded_image, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "NUM_EPOCHS=100\n",
    "LR=3E-4\n",
    "\n",
    "\n",
    "print(f\"{device}, Device used\")\n",
    "\n",
    "model = Decoder().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "mse = nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd693fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDataset2(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, paths):\n",
    "        self.paths = paths\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        o_img, e_img = encode_image(self.paths[index])\n",
    "        o_img = torch.tensor(np.moveaxis(o_img, [0, 1, 2], [1, 2, 0]))\n",
    "        e_img = prepareTensor(e_img)\n",
    "        return o_img, e_img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = ConvDataset2(image_paths)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e691e18",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m epoch \u001b[38;5;241m!=\u001b[39m NUM_EPOCHS:\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mo_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m, in \u001b[0;36mConvDataset2.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m----> 7\u001b[0m     o_img, e_img \u001b[38;5;241m=\u001b[39m \u001b[43mencode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     o_img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mmoveaxis(o_img, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m      9\u001b[0m     e_img \u001b[38;5;241m=\u001b[39m prepareTensor(e_img)\n",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m, in \u001b[0;36mencode_image\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im, \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/decomposition/_base.py:145\u001b[0m, in \u001b[0;36m_BasePCA.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    136\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    138\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    140\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    144\u001b[0m )\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_is_centered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/decomposition/_base.py:155\u001b[0m, in \u001b[0;36m_BasePCA._transform\u001b[0;34m(self, X, xp, x_is_centered)\u001b[0m\n\u001b[1;32m    148\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x_is_centered:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# Apply the centering after the projection.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# For dense X this avoids copying or mutating the data passed by\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# the caller.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# For sparse X it keeps sparsity and avoids having to wrap X into\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# a linear operator.\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     X_transformed \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhiten:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# For some solvers (such as \"arpack\" and \"covariance_eigh\"), on\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# rank deficient data, some components can have a variance\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# arbitrarily close to zero, leading to non-finite results when\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# whitening. To avoid this problem we clip the variance below.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     scale \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplained_variance_)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/_array_api.py:419\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.reshape\u001b[0;34m(self, x, shape, copy)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\u001b[38;5;28mself\u001b[39m, arrays, \u001b[38;5;241m*\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39mconcatenate(arrays, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, shape, \u001b[38;5;241m*\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    420\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m    The Array API specification requires shape to be a tuple.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m    https://data-apis.org/array-api/latest/API_specification/generated/array_api.reshape.html\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shape, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "while epoch != NUM_EPOCHS:\n",
    "    optimizer.zero_grad()\n",
    "    for data in dataloader:\n",
    "        o_img, sample = data\n",
    "        sample = sample.to(device)\n",
    "        o_img = o_img.to(device)\n",
    "        out = model(sample)\n",
    "        loss = mse(out, o_img)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch}/{NUM_EPOCHS}, {loss.item()}\")\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "923e2bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x70971f51daf0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = read_image(image_paths[0])\n",
    "o_img, e_img = encode_image(image_paths[0])\n",
    "\n",
    "out = model(prepareTensor(e_img).unsqueeze(0).to(device)).to(\"cpu\")\n",
    "\n",
    "out = out * 255\n",
    "np.uint8(out.squeeze().permute(1, 2, 0).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aadc2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "class TrainingDashboard():\n",
    "    def __init__(self):\n",
    "        plt.style.use(\"seaborn-v0_8-dark\")\n",
    "        self.fig = plt.figure()\n",
    "        self.oimg_ax = self.fig.add_axes((0, 0.5, 0.5, 0.5))\n",
    "        self.timg_ax = self.fig.add_axes((0.5, 0.5, 0.5, 0.5))\n",
    "\n",
    "        self.loss_ax = self.fig.add_axes((0, 0, 1, 0.5))\n",
    "\n",
    "        self.oimg_ax.axis(\"off\")\n",
    "        self.timg_ax.axis(\"off\")\n",
    "\n",
    "        self.loss_ax.axis(\"off\")\n",
    "\n",
    "        \n",
    "    \n",
    "    def update(self):\n",
    "        self.fig.canvas.flush_events()\n",
    "\n",
    "    def loss_axis(self, epoch, loss):\n",
    "        self.loss_ax.plot(epoch, loss, \"ro--\")\n",
    "\n",
    "    def setorg_img(self, image, cmap=None):\n",
    "        assert image is np.ndarray and image.dtype == np.uint8\n",
    "        self.oimg_ax.imshow(image, cmap=cmap)\n",
    "\n",
    "\n",
    "    def setrecon_img(self, image, cmap=None):\n",
    "        assert image is np.ndarray and image.dtype == np.uint8\n",
    "        self.timg_ax.imshow(image, cmap=cmap)\n",
    "\n",
    "\n",
    "dash = TrainingDashboard()\n",
    "\n",
    "import time\n",
    "for i in range(0, 10):\n",
    "    dash.loss_axis(i, 5)\n",
    "    dash.update()\n",
    "    plt.pause(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee008c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
