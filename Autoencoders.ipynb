{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30383d2f-0f0c-4c64-ba07-c1061cef65d8",
   "metadata": {},
   "source": [
    "# Understanding Autoencoders\n",
    "\n",
    "\n",
    "## Dataset Source\n",
    "\n",
    "- [Kaggle]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835d253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208fcda3-fb6d-4d3d-acf0-edaf0a07cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dataset From Source...\n",
      "+ '[' '!' -d dataset ']'\n",
      "+ echo 'Dataset Directory already exist!'\n",
      "Dataset Directory already exist!\n"
     ]
    }
   ],
   "source": [
    "!bash dataset_fetch.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "998923ed-7651-4daf-8d8b-78f636960975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Cell\n",
    "\n",
    "\n",
    "def helper_imageGrid(image_paths, cols=4):\n",
    "    img_count = len(image_paths)\n",
    "    rows = math.ceil(img_count / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 20))\n",
    "    irow, icol = 0, 0\n",
    "    for path in image_paths:\n",
    "        ax = axes[irow][icol]\n",
    "        ax.imshow(Image.open(path))\n",
    "        title = path.split(\"/\")[-2]\n",
    "        #ax.title(path)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        icol += 1\n",
    "        if icol % cols == 0:\n",
    "            icol = 0\n",
    "            irow += 1\n",
    "\n",
    "        \n",
    "    \n",
    "    return fig\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def helper_fetch_localmodel(name=\"autoencoder\", device=device):\n",
    "    max_name = None\n",
    "    max_num = 0\n",
    "    for x in os.listdir():\n",
    "        if a := re.match(\"autoencoder_\\\\d+\", x):\n",
    "            name = a.group()\n",
    "            num = int(name.split(\"_\")[-1])\n",
    "            max_num = num if max_num < num else max_num\n",
    "    if max_num > 0:\n",
    "        return torch.load(f\"{name}_{max_num}\", map_location=torch.device(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9cedefe-63ed-490c-81e5-ada3c922cd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of Images:  {(300, 300)}\n",
      "Count of Images:  1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "image_paths = [ f\"dataset/GAID/Soul/{x}\" for x in os.listdir(\"dataset/GAID/Soul\") ]\n",
    "\n",
    "\n",
    "sizes = set()\n",
    "for x in image_paths:\n",
    "    img = Image.open(x)\n",
    "    sizes.add(img.size)\n",
    "    img.close()\n",
    "\n",
    "print(\"Sizes of Images: \", sizes)\n",
    "print(\"Count of Images: \", len(image_paths))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "48235302-dea9-4055-bdf4-a6b36d1a9bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is Available!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "100x100 --> 10x10 --> 10 --> 10x10 --> 100x100\n",
    "\n",
    "'''\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(100**2, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100**2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ReconstructionLoss(reproduced, original): \n",
    "    return torch.sum((original - reproduced)**2) / len(original)\n",
    "\n",
    "print(f\"{device} is Available!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c8ed8a-cec3-4d2d-b824-ccafe1f25702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def todata(path):\n",
    "    image = Image.open(path).convert(\"L\").resize((100, 100))\n",
    "    tensor = transforms.ToTensor()(image)\n",
    "    tensor = nn.Flatten(0)(tensor)\n",
    "    image.close()\n",
    "    return tensor\n",
    "    \n",
    "def toimg(data):\n",
    "    data = nn.Sigmoid()(data.view(100, 100)) * 255\n",
    "    return np.uint8(data.detach().numpy())\n",
    "    \n",
    "auto = Autoencoder().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8b740c-cdf5-4422-ba0c-b3da3d99f813",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib tk\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "raw_img = fig.add_axes([0, 0.5, 0.5 - 0.02, 0.5 - 0.02])\n",
    "trans_img = fig.add_axes([0.5, 0.5, 0.5 - 0.02, 0.5 - 0.02])\n",
    "\n",
    "loss_ax = fig.add_axes([0, 0, 1 - 0.02, 0.5 - 0.02])\n",
    "\n",
    "raw_img.axis(\"off\")\n",
    "trans_img.axis(\"off\")\n",
    "loss_ax.axis(\"off\")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "loss_ax.set_xlim(left=0, right=epochs)\n",
    "optimizer = torch.optim.Adam(auto.parameters(),lr=0.001)\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    sample_path = random.choice(image_paths)\n",
    "    sample_data = todata(sample_path)\n",
    "    sample_img = toimg(sample_data)\n",
    "\n",
    "    raw_img.imshow(sample_img, cmap=\"ocean_r\")\n",
    "    timg = toimg(auto(sample_data.to(device)).to(\"cpu\"))\n",
    "    trans_img.imshow(timg, cmap=\"ocean_r\")\n",
    "    \n",
    "\n",
    "\n",
    "    for path in image_paths:\n",
    "        optimizer.zero_grad()\n",
    "        sample = todata(path).to(device)\n",
    "        op = auto(sample).to(device)\n",
    "        loss = ReconstructionLoss(sample, op)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_ax.plot(epoch, loss.to(\"cpu\").item(), \"ro\")\n",
    "    fig.canvas.flush_events()\n",
    "    fig.show()\n",
    "    print(f\"{epoch} done, {loss.to(\"cpu\").item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7b19f-be7f-443d-8087-4efbd5061626",
   "metadata": {},
   "source": [
    "show_count = 10\n",
    "\n",
    "fig, axes = plt.subplots(show_count, 2, figsize=(10, show_count * 5))\n",
    "\n",
    "for i, path in enumerate(image_paths[:show_count]):\n",
    "    data = todata(path).to(device)\n",
    "    infer = auto(data).to(\"cpu\")\n",
    "    data = data.to(\"cpu\")\n",
    "    axes[i][0].imshow(toimg(data), cmap=\"gray\")\n",
    "    axes[i][0].axis(\"off\")\n",
    "    axes[i][1].imshow(toimg(infer), cmap=\"gray\")\n",
    "    axes[i][1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d374a26-7535-4cfb-b384-00ecab347924",
   "metadata": {},
   "source": [
    "# Understanding and creating a Convolutional Autoencoer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8a9cbc-82e4-41a9-95f1-d5fbaa2f6327",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=10, out_channels=5, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=5, out_channels=5, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Flatten(1)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(1, (5, 3, 3)),\n",
    "            nn.UpsamplingBilinear2d(None, (3, 3)),\n",
    "            nn.ConvTranspose2d(in_channels=5, out_channels=5, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.UpsamplingBilinear2d(None, (3, 3)),\n",
    "            nn.ConvTranspose2d(in_channels=5, out_channels=10, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.UpsamplingBilinear2d(None, (3, 3)),\n",
    "            nn.ConvTranspose2d(in_channels=10, out_channels=1, kernel_size=3, padding=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f8cf82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTensor(path):\n",
    "    img = Image.open(path).resize((99, 99)).convert(\"L\")\n",
    "    data = transforms.ToTensor()(img)\n",
    "    img.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def toimg(data):\n",
    "   return np.uint8(data.view(99, 99).detach().numpy() * 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16fd6140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CoverArtsDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.paths = image_paths\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return prepareTensor(self.paths[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7065e637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n",
      "Number Of Epoch Done: 0/1000\n",
      "Number Of Epoch Done: 1/1000\n",
      "Number Of Epoch Done: 2/1000\n",
      "Number Of Epoch Done: 3/1000\n",
      "Number Of Epoch Done: 4/1000\n",
      "Number Of Epoch Done: 5/1000\n",
      "Number Of Epoch Done: 6/1000\n",
      "Number Of Epoch Done: 7/1000\n",
      "Number Of Epoch Done: 8/1000\n",
      "Number Of Epoch Done: 9/1000\n",
      "Number Of Epoch Done: 10/1000\n",
      "Number Of Epoch Done: 11/1000\n",
      "Number Of Epoch Done: 12/1000\n",
      "Number Of Epoch Done: 13/1000\n",
      "Number Of Epoch Done: 14/1000\n",
      "Number Of Epoch Done: 15/1000\n",
      "Number Of Epoch Done: 16/1000\n",
      "Number Of Epoch Done: 17/1000\n",
      "Number Of Epoch Done: 18/1000\n",
      "Number Of Epoch Done: 19/1000\n",
      "Number Of Epoch Done: 20/1000\n",
      "Number Of Epoch Done: 21/1000\n",
      "Number Of Epoch Done: 22/1000\n",
      "Number Of Epoch Done: 23/1000\n",
      "Number Of Epoch Done: 24/1000\n",
      "Number Of Epoch Done: 25/1000\n",
      "Number Of Epoch Done: 26/1000\n",
      "Number Of Epoch Done: 27/1000\n",
      "Number Of Epoch Done: 28/1000\n",
      "Number Of Epoch Done: 29/1000\n",
      "Number Of Epoch Done: 30/1000\n",
      "Number Of Epoch Done: 31/1000\n",
      "Number Of Epoch Done: 32/1000\n",
      "Number Of Epoch Done: 33/1000\n",
      "Number Of Epoch Done: 34/1000\n",
      "Number Of Epoch Done: 35/1000\n",
      "Number Of Epoch Done: 36/1000\n",
      "Number Of Epoch Done: 37/1000\n",
      "Number Of Epoch Done: 38/1000\n",
      "Number Of Epoch Done: 39/1000\n",
      "Number Of Epoch Done: 40/1000\n",
      "Number Of Epoch Done: 41/1000\n",
      "Number Of Epoch Done: 42/1000\n",
      "Number Of Epoch Done: 43/1000\n",
      "Number Of Epoch Done: 44/1000\n",
      "Number Of Epoch Done: 45/1000\n",
      "Number Of Epoch Done: 46/1000\n",
      "Number Of Epoch Done: 47/1000\n",
      "Number Of Epoch Done: 48/1000\n",
      "Number Of Epoch Done: 49/1000\n",
      "Number Of Epoch Done: 50/1000\n",
      "Number Of Epoch Done: 51/1000\n",
      "Number Of Epoch Done: 52/1000\n",
      "Number Of Epoch Done: 53/1000\n",
      "Number Of Epoch Done: 54/1000\n",
      "Number Of Epoch Done: 55/1000\n",
      "Number Of Epoch Done: 56/1000\n",
      "Number Of Epoch Done: 57/1000\n",
      "Number Of Epoch Done: 58/1000\n",
      "Number Of Epoch Done: 59/1000\n",
      "Number Of Epoch Done: 60/1000\n",
      "Number Of Epoch Done: 61/1000\n",
      "Number Of Epoch Done: 62/1000\n",
      "Number Of Epoch Done: 63/1000\n",
      "Number Of Epoch Done: 64/1000\n",
      "Number Of Epoch Done: 65/1000\n",
      "Number Of Epoch Done: 66/1000\n",
      "Number Of Epoch Done: 67/1000\n",
      "Number Of Epoch Done: 68/1000\n",
      "Number Of Epoch Done: 69/1000\n",
      "Number Of Epoch Done: 70/1000\n",
      "Number Of Epoch Done: 71/1000\n",
      "Number Of Epoch Done: 72/1000\n",
      "Number Of Epoch Done: 73/1000\n",
      "Number Of Epoch Done: 74/1000\n",
      "Number Of Epoch Done: 75/1000\n",
      "Number Of Epoch Done: 76/1000\n",
      "Number Of Epoch Done: 77/1000\n",
      "Number Of Epoch Done: 78/1000\n",
      "Number Of Epoch Done: 79/1000\n",
      "Number Of Epoch Done: 80/1000\n",
      "Number Of Epoch Done: 81/1000\n",
      "Number Of Epoch Done: 82/1000\n",
      "Number Of Epoch Done: 83/1000\n",
      "Number Of Epoch Done: 84/1000\n",
      "Number Of Epoch Done: 85/1000\n",
      "Number Of Epoch Done: 86/1000\n",
      "Number Of Epoch Done: 87/1000\n",
      "Number Of Epoch Done: 88/1000\n",
      "Number Of Epoch Done: 89/1000\n",
      "Number Of Epoch Done: 90/1000\n",
      "Number Of Epoch Done: 91/1000\n",
      "Number Of Epoch Done: 92/1000\n",
      "Number Of Epoch Done: 93/1000\n",
      "Number Of Epoch Done: 94/1000\n",
      "Number Of Epoch Done: 95/1000\n",
      "Number Of Epoch Done: 96/1000\n",
      "Number Of Epoch Done: 97/1000\n",
      "Number Of Epoch Done: 98/1000\n",
      "Number Of Epoch Done: 99/1000\n",
      "Number Of Epoch Done: 100/1000\n",
      "Number Of Epoch Done: 101/1000\n",
      "Number Of Epoch Done: 102/1000\n",
      "Number Of Epoch Done: 103/1000\n",
      "Number Of Epoch Done: 104/1000\n",
      "Number Of Epoch Done: 105/1000\n",
      "Number Of Epoch Done: 106/1000\n",
      "Number Of Epoch Done: 107/1000\n",
      "Number Of Epoch Done: 108/1000\n",
      "Number Of Epoch Done: 109/1000\n",
      "Number Of Epoch Done: 110/1000\n",
      "Number Of Epoch Done: 111/1000\n",
      "Number Of Epoch Done: 112/1000\n",
      "Number Of Epoch Done: 113/1000\n",
      "Number Of Epoch Done: 114/1000\n",
      "Number Of Epoch Done: 115/1000\n",
      "Number Of Epoch Done: 116/1000\n",
      "Number Of Epoch Done: 117/1000\n",
      "Number Of Epoch Done: 118/1000\n",
      "Number Of Epoch Done: 119/1000\n",
      "Number Of Epoch Done: 120/1000\n",
      "Number Of Epoch Done: 121/1000\n",
      "Number Of Epoch Done: 122/1000\n",
      "Number Of Epoch Done: 123/1000\n",
      "Number Of Epoch Done: 124/1000\n",
      "Number Of Epoch Done: 125/1000\n",
      "Number Of Epoch Done: 126/1000\n",
      "Number Of Epoch Done: 127/1000\n",
      "Number Of Epoch Done: 128/1000\n",
      "Number Of Epoch Done: 129/1000\n",
      "Number Of Epoch Done: 130/1000\n",
      "Number Of Epoch Done: 131/1000\n",
      "Number Of Epoch Done: 132/1000\n",
      "Number Of Epoch Done: 133/1000\n",
      "Number Of Epoch Done: 134/1000\n",
      "Number Of Epoch Done: 135/1000\n",
      "Number Of Epoch Done: 136/1000\n",
      "Number Of Epoch Done: 137/1000\n",
      "Number Of Epoch Done: 138/1000\n",
      "Number Of Epoch Done: 139/1000\n",
      "Number Of Epoch Done: 140/1000\n",
      "Number Of Epoch Done: 141/1000\n",
      "Number Of Epoch Done: 142/1000\n",
      "Number Of Epoch Done: 143/1000\n",
      "Number Of Epoch Done: 144/1000\n",
      "Number Of Epoch Done: 145/1000\n",
      "Number Of Epoch Done: 146/1000\n",
      "Number Of Epoch Done: 147/1000\n",
      "Number Of Epoch Done: 148/1000\n",
      "Number Of Epoch Done: 149/1000\n",
      "Number Of Epoch Done: 150/1000\n",
      "Number Of Epoch Done: 151/1000\n",
      "Number Of Epoch Done: 152/1000\n",
      "Number Of Epoch Done: 153/1000\n",
      "Number Of Epoch Done: 154/1000\n",
      "Number Of Epoch Done: 155/1000\n",
      "Number Of Epoch Done: 156/1000\n",
      "Number Of Epoch Done: 157/1000\n",
      "Number Of Epoch Done: 158/1000\n",
      "Number Of Epoch Done: 159/1000\n",
      "Number Of Epoch Done: 160/1000\n",
      "Number Of Epoch Done: 161/1000\n",
      "Number Of Epoch Done: 162/1000\n",
      "Number Of Epoch Done: 163/1000\n",
      "Number Of Epoch Done: 164/1000\n",
      "Number Of Epoch Done: 165/1000\n",
      "Number Of Epoch Done: 166/1000\n",
      "Number Of Epoch Done: 167/1000\n",
      "Number Of Epoch Done: 168/1000\n",
      "Number Of Epoch Done: 169/1000\n",
      "Number Of Epoch Done: 170/1000\n",
      "Number Of Epoch Done: 171/1000\n",
      "Number Of Epoch Done: 172/1000\n",
      "Number Of Epoch Done: 173/1000\n",
      "Number Of Epoch Done: 174/1000\n",
      "Number Of Epoch Done: 175/1000\n",
      "Number Of Epoch Done: 176/1000\n",
      "Number Of Epoch Done: 177/1000\n",
      "Number Of Epoch Done: 178/1000\n",
      "Number Of Epoch Done: 179/1000\n",
      "Number Of Epoch Done: 180/1000\n",
      "Number Of Epoch Done: 181/1000\n",
      "Number Of Epoch Done: 182/1000\n",
      "Number Of Epoch Done: 183/1000\n",
      "Number Of Epoch Done: 184/1000\n",
      "Number Of Epoch Done: 185/1000\n",
      "Number Of Epoch Done: 186/1000\n",
      "Number Of Epoch Done: 187/1000\n",
      "Number Of Epoch Done: 188/1000\n",
      "Number Of Epoch Done: 189/1000\n",
      "Number Of Epoch Done: 190/1000\n",
      "Number Of Epoch Done: 191/1000\n",
      "Number Of Epoch Done: 192/1000\n",
      "Number Of Epoch Done: 193/1000\n",
      "Number Of Epoch Done: 194/1000\n",
      "Number Of Epoch Done: 195/1000\n",
      "Number Of Epoch Done: 196/1000\n",
      "Number Of Epoch Done: 197/1000\n",
      "Number Of Epoch Done: 198/1000\n",
      "Number Of Epoch Done: 199/1000\n",
      "Number Of Epoch Done: 200/1000\n",
      "Number Of Epoch Done: 201/1000\n",
      "Number Of Epoch Done: 202/1000\n",
      "Number Of Epoch Done: 203/1000\n",
      "Number Of Epoch Done: 204/1000\n",
      "Number Of Epoch Done: 205/1000\n",
      "Number Of Epoch Done: 206/1000\n",
      "Number Of Epoch Done: 207/1000\n",
      "Number Of Epoch Done: 208/1000\n",
      "Number Of Epoch Done: 209/1000\n",
      "Number Of Epoch Done: 210/1000\n",
      "Number Of Epoch Done: 211/1000\n",
      "Number Of Epoch Done: 212/1000\n",
      "Number Of Epoch Done: 213/1000\n",
      "Number Of Epoch Done: 214/1000\n",
      "Number Of Epoch Done: 215/1000\n",
      "Number Of Epoch Done: 216/1000\n",
      "Number Of Epoch Done: 217/1000\n",
      "Number Of Epoch Done: 218/1000\n",
      "Number Of Epoch Done: 219/1000\n",
      "Number Of Epoch Done: 220/1000\n",
      "Number Of Epoch Done: 221/1000\n",
      "Number Of Epoch Done: 222/1000\n",
      "Number Of Epoch Done: 223/1000\n",
      "Number Of Epoch Done: 224/1000\n",
      "Number Of Epoch Done: 225/1000\n",
      "Number Of Epoch Done: 226/1000\n",
      "Number Of Epoch Done: 227/1000\n",
      "Number Of Epoch Done: 228/1000\n",
      "Number Of Epoch Done: 229/1000\n",
      "Number Of Epoch Done: 230/1000\n",
      "Number Of Epoch Done: 231/1000\n",
      "Number Of Epoch Done: 232/1000\n",
      "Number Of Epoch Done: 233/1000\n",
      "Number Of Epoch Done: 234/1000\n",
      "Number Of Epoch Done: 235/1000\n",
      "Number Of Epoch Done: 236/1000\n",
      "Number Of Epoch Done: 237/1000\n",
      "Number Of Epoch Done: 238/1000\n",
      "Number Of Epoch Done: 239/1000\n",
      "Number Of Epoch Done: 240/1000\n",
      "Number Of Epoch Done: 241/1000\n",
      "Number Of Epoch Done: 242/1000\n",
      "Number Of Epoch Done: 243/1000\n",
      "Number Of Epoch Done: 244/1000\n",
      "Number Of Epoch Done: 245/1000\n",
      "Number Of Epoch Done: 246/1000\n",
      "Number Of Epoch Done: 247/1000\n",
      "Number Of Epoch Done: 248/1000\n",
      "Number Of Epoch Done: 249/1000\n",
      "Number Of Epoch Done: 250/1000\n",
      "Number Of Epoch Done: 251/1000\n",
      "Number Of Epoch Done: 252/1000\n",
      "Number Of Epoch Done: 253/1000\n",
      "Number Of Epoch Done: 254/1000\n",
      "Number Of Epoch Done: 255/1000\n",
      "Number Of Epoch Done: 256/1000\n",
      "Number Of Epoch Done: 257/1000\n",
      "Number Of Epoch Done: 258/1000\n",
      "Number Of Epoch Done: 259/1000\n",
      "Number Of Epoch Done: 260/1000\n",
      "Number Of Epoch Done: 261/1000\n",
      "Number Of Epoch Done: 262/1000\n",
      "Number Of Epoch Done: 263/1000\n",
      "Number Of Epoch Done: 264/1000\n",
      "Number Of Epoch Done: 265/1000\n",
      "Number Of Epoch Done: 266/1000\n",
      "Number Of Epoch Done: 267/1000\n",
      "Number Of Epoch Done: 268/1000\n",
      "Number Of Epoch Done: 269/1000\n",
      "Number Of Epoch Done: 270/1000\n",
      "Number Of Epoch Done: 271/1000\n",
      "Number Of Epoch Done: 272/1000\n",
      "Number Of Epoch Done: 273/1000\n",
      "Number Of Epoch Done: 274/1000\n",
      "Number Of Epoch Done: 275/1000\n",
      "Number Of Epoch Done: 276/1000\n",
      "Number Of Epoch Done: 277/1000\n",
      "Number Of Epoch Done: 278/1000\n",
      "Number Of Epoch Done: 279/1000\n",
      "Number Of Epoch Done: 280/1000\n",
      "Number Of Epoch Done: 281/1000\n",
      "Number Of Epoch Done: 282/1000\n",
      "Number Of Epoch Done: 283/1000\n",
      "Number Of Epoch Done: 284/1000\n",
      "Number Of Epoch Done: 285/1000\n",
      "Number Of Epoch Done: 286/1000\n",
      "Number Of Epoch Done: 287/1000\n",
      "Number Of Epoch Done: 288/1000\n",
      "Number Of Epoch Done: 289/1000\n",
      "Number Of Epoch Done: 290/1000\n",
      "Number Of Epoch Done: 291/1000\n",
      "Number Of Epoch Done: 292/1000\n",
      "Number Of Epoch Done: 293/1000\n",
      "Number Of Epoch Done: 294/1000\n",
      "Number Of Epoch Done: 295/1000\n",
      "Number Of Epoch Done: 296/1000\n",
      "Number Of Epoch Done: 297/1000\n",
      "Number Of Epoch Done: 298/1000\n",
      "Number Of Epoch Done: 299/1000\n",
      "Number Of Epoch Done: 300/1000\n",
      "Number Of Epoch Done: 301/1000\n",
      "Number Of Epoch Done: 302/1000\n",
      "Number Of Epoch Done: 303/1000\n",
      "Number Of Epoch Done: 304/1000\n",
      "Number Of Epoch Done: 305/1000\n",
      "Number Of Epoch Done: 306/1000\n",
      "Number Of Epoch Done: 307/1000\n",
      "Number Of Epoch Done: 308/1000\n",
      "Number Of Epoch Done: 309/1000\n",
      "Number Of Epoch Done: 310/1000\n",
      "Number Of Epoch Done: 311/1000\n",
      "Number Of Epoch Done: 312/1000\n",
      "Number Of Epoch Done: 313/1000\n",
      "Number Of Epoch Done: 314/1000\n",
      "Number Of Epoch Done: 315/1000\n",
      "Number Of Epoch Done: 316/1000\n",
      "Number Of Epoch Done: 317/1000\n",
      "Number Of Epoch Done: 318/1000\n",
      "Number Of Epoch Done: 319/1000\n",
      "Number Of Epoch Done: 320/1000\n",
      "Number Of Epoch Done: 321/1000\n",
      "Number Of Epoch Done: 322/1000\n",
      "Number Of Epoch Done: 323/1000\n",
      "Number Of Epoch Done: 324/1000\n",
      "Number Of Epoch Done: 325/1000\n",
      "Number Of Epoch Done: 326/1000\n",
      "Number Of Epoch Done: 327/1000\n",
      "Number Of Epoch Done: 328/1000\n",
      "Number Of Epoch Done: 329/1000\n",
      "Number Of Epoch Done: 330/1000\n",
      "Number Of Epoch Done: 331/1000\n",
      "Number Of Epoch Done: 332/1000\n",
      "Number Of Epoch Done: 333/1000\n",
      "Number Of Epoch Done: 334/1000\n",
      "Number Of Epoch Done: 335/1000\n",
      "Number Of Epoch Done: 336/1000\n",
      "Number Of Epoch Done: 337/1000\n",
      "Number Of Epoch Done: 338/1000\n",
      "Number Of Epoch Done: 339/1000\n",
      "Number Of Epoch Done: 340/1000\n",
      "Number Of Epoch Done: 341/1000\n",
      "Number Of Epoch Done: 342/1000\n",
      "Number Of Epoch Done: 343/1000\n",
      "Number Of Epoch Done: 344/1000\n",
      "Number Of Epoch Done: 345/1000\n",
      "Number Of Epoch Done: 346/1000\n",
      "Number Of Epoch Done: 347/1000\n",
      "Number Of Epoch Done: 348/1000\n",
      "Number Of Epoch Done: 349/1000\n",
      "Number Of Epoch Done: 350/1000\n",
      "Number Of Epoch Done: 351/1000\n",
      "Number Of Epoch Done: 352/1000\n",
      "Number Of Epoch Done: 353/1000\n",
      "Number Of Epoch Done: 354/1000\n",
      "Number Of Epoch Done: 355/1000\n",
      "Number Of Epoch Done: 356/1000\n",
      "Number Of Epoch Done: 357/1000\n",
      "Number Of Epoch Done: 358/1000\n",
      "Number Of Epoch Done: 359/1000\n",
      "Number Of Epoch Done: 360/1000\n",
      "Number Of Epoch Done: 361/1000\n",
      "Number Of Epoch Done: 362/1000\n",
      "Number Of Epoch Done: 363/1000\n",
      "Number Of Epoch Done: 364/1000\n",
      "Number Of Epoch Done: 365/1000\n",
      "Number Of Epoch Done: 366/1000\n",
      "Number Of Epoch Done: 367/1000\n",
      "Number Of Epoch Done: 368/1000\n",
      "Number Of Epoch Done: 369/1000\n",
      "Number Of Epoch Done: 370/1000\n",
      "Number Of Epoch Done: 371/1000\n",
      "Number Of Epoch Done: 372/1000\n",
      "Number Of Epoch Done: 373/1000\n",
      "Number Of Epoch Done: 374/1000\n",
      "Number Of Epoch Done: 375/1000\n",
      "Number Of Epoch Done: 376/1000\n",
      "Number Of Epoch Done: 377/1000\n",
      "Number Of Epoch Done: 378/1000\n",
      "Number Of Epoch Done: 379/1000\n",
      "Number Of Epoch Done: 380/1000\n",
      "Number Of Epoch Done: 381/1000\n",
      "Number Of Epoch Done: 382/1000\n",
      "Number Of Epoch Done: 383/1000\n",
      "Number Of Epoch Done: 384/1000\n",
      "Number Of Epoch Done: 385/1000\n",
      "Number Of Epoch Done: 386/1000\n",
      "Number Of Epoch Done: 387/1000\n",
      "Number Of Epoch Done: 388/1000\n",
      "Number Of Epoch Done: 389/1000\n",
      "Number Of Epoch Done: 390/1000\n",
      "Number Of Epoch Done: 391/1000\n",
      "Number Of Epoch Done: 392/1000\n",
      "Number Of Epoch Done: 393/1000\n",
      "Number Of Epoch Done: 394/1000\n",
      "Number Of Epoch Done: 395/1000\n",
      "Number Of Epoch Done: 396/1000\n",
      "Number Of Epoch Done: 397/1000\n",
      "Number Of Epoch Done: 398/1000\n",
      "Number Of Epoch Done: 399/1000\n",
      "Number Of Epoch Done: 400/1000\n",
      "Number Of Epoch Done: 401/1000\n",
      "Number Of Epoch Done: 402/1000\n",
      "Number Of Epoch Done: 403/1000\n",
      "Number Of Epoch Done: 404/1000\n",
      "Number Of Epoch Done: 405/1000\n",
      "Number Of Epoch Done: 406/1000\n",
      "Number Of Epoch Done: 407/1000\n",
      "Number Of Epoch Done: 408/1000\n",
      "Number Of Epoch Done: 409/1000\n",
      "Number Of Epoch Done: 410/1000\n",
      "Number Of Epoch Done: 411/1000\n",
      "Number Of Epoch Done: 412/1000\n",
      "Number Of Epoch Done: 413/1000\n",
      "Number Of Epoch Done: 414/1000\n",
      "Number Of Epoch Done: 415/1000\n",
      "Number Of Epoch Done: 416/1000\n",
      "Number Of Epoch Done: 417/1000\n",
      "Number Of Epoch Done: 418/1000\n",
      "Number Of Epoch Done: 419/1000\n",
      "Number Of Epoch Done: 420/1000\n",
      "Number Of Epoch Done: 421/1000\n",
      "Number Of Epoch Done: 422/1000\n",
      "Number Of Epoch Done: 423/1000\n",
      "Number Of Epoch Done: 424/1000\n",
      "Number Of Epoch Done: 425/1000\n",
      "Number Of Epoch Done: 426/1000\n",
      "Number Of Epoch Done: 427/1000\n",
      "Number Of Epoch Done: 428/1000\n",
      "Number Of Epoch Done: 429/1000\n",
      "Number Of Epoch Done: 430/1000\n",
      "Number Of Epoch Done: 431/1000\n",
      "Number Of Epoch Done: 432/1000\n",
      "Number Of Epoch Done: 433/1000\n",
      "Number Of Epoch Done: 434/1000\n",
      "Number Of Epoch Done: 435/1000\n",
      "Number Of Epoch Done: 436/1000\n",
      "Number Of Epoch Done: 437/1000\n",
      "Number Of Epoch Done: 438/1000\n",
      "Number Of Epoch Done: 439/1000\n",
      "Number Of Epoch Done: 440/1000\n",
      "Number Of Epoch Done: 441/1000\n",
      "Number Of Epoch Done: 442/1000\n",
      "Number Of Epoch Done: 443/1000\n",
      "Number Of Epoch Done: 444/1000\n",
      "Number Of Epoch Done: 445/1000\n",
      "Number Of Epoch Done: 446/1000\n",
      "Number Of Epoch Done: 447/1000\n",
      "Number Of Epoch Done: 448/1000\n",
      "Number Of Epoch Done: 449/1000\n",
      "Number Of Epoch Done: 450/1000\n",
      "Number Of Epoch Done: 451/1000\n",
      "Number Of Epoch Done: 452/1000\n",
      "Number Of Epoch Done: 453/1000\n",
      "Number Of Epoch Done: 454/1000\n",
      "Number Of Epoch Done: 455/1000\n",
      "Number Of Epoch Done: 456/1000\n",
      "Number Of Epoch Done: 457/1000\n",
      "Number Of Epoch Done: 458/1000\n",
      "Number Of Epoch Done: 459/1000\n",
      "Number Of Epoch Done: 460/1000\n",
      "Number Of Epoch Done: 461/1000\n",
      "Number Of Epoch Done: 462/1000\n",
      "Number Of Epoch Done: 463/1000\n",
      "Number Of Epoch Done: 464/1000\n",
      "Number Of Epoch Done: 465/1000\n",
      "Number Of Epoch Done: 466/1000\n",
      "Number Of Epoch Done: 467/1000\n",
      "Number Of Epoch Done: 468/1000\n",
      "Number Of Epoch Done: 469/1000\n",
      "Number Of Epoch Done: 470/1000\n",
      "Number Of Epoch Done: 471/1000\n",
      "Number Of Epoch Done: 472/1000\n",
      "Number Of Epoch Done: 473/1000\n",
      "Number Of Epoch Done: 474/1000\n",
      "Number Of Epoch Done: 475/1000\n",
      "Number Of Epoch Done: 476/1000\n",
      "Number Of Epoch Done: 477/1000\n",
      "Number Of Epoch Done: 478/1000\n",
      "Number Of Epoch Done: 479/1000\n",
      "Number Of Epoch Done: 480/1000\n",
      "Number Of Epoch Done: 481/1000\n",
      "Number Of Epoch Done: 482/1000\n",
      "Number Of Epoch Done: 483/1000\n",
      "Number Of Epoch Done: 484/1000\n",
      "Number Of Epoch Done: 485/1000\n",
      "Number Of Epoch Done: 486/1000\n",
      "Number Of Epoch Done: 487/1000\n",
      "Number Of Epoch Done: 488/1000\n",
      "Number Of Epoch Done: 489/1000\n",
      "Number Of Epoch Done: 490/1000\n",
      "Number Of Epoch Done: 491/1000\n",
      "Number Of Epoch Done: 492/1000\n",
      "Number Of Epoch Done: 493/1000\n",
      "Number Of Epoch Done: 494/1000\n",
      "Number Of Epoch Done: 495/1000\n",
      "Number Of Epoch Done: 496/1000\n",
      "Number Of Epoch Done: 497/1000\n",
      "Number Of Epoch Done: 498/1000\n",
      "Number Of Epoch Done: 499/1000\n",
      "Number Of Epoch Done: 500/1000\n",
      "Number Of Epoch Done: 501/1000\n",
      "Number Of Epoch Done: 502/1000\n",
      "Number Of Epoch Done: 503/1000\n",
      "Number Of Epoch Done: 504/1000\n",
      "Number Of Epoch Done: 505/1000\n",
      "Number Of Epoch Done: 506/1000\n",
      "Number Of Epoch Done: 507/1000\n",
      "Number Of Epoch Done: 508/1000\n",
      "Number Of Epoch Done: 509/1000\n",
      "Number Of Epoch Done: 510/1000\n",
      "Number Of Epoch Done: 511/1000\n",
      "Number Of Epoch Done: 512/1000\n",
      "Number Of Epoch Done: 513/1000\n",
      "Number Of Epoch Done: 514/1000\n",
      "Number Of Epoch Done: 515/1000\n",
      "Number Of Epoch Done: 516/1000\n",
      "Number Of Epoch Done: 517/1000\n",
      "Number Of Epoch Done: 518/1000\n",
      "Number Of Epoch Done: 519/1000\n",
      "Number Of Epoch Done: 520/1000\n",
      "Number Of Epoch Done: 521/1000\n",
      "Number Of Epoch Done: 522/1000\n",
      "Number Of Epoch Done: 523/1000\n",
      "Number Of Epoch Done: 524/1000\n",
      "Number Of Epoch Done: 525/1000\n",
      "Number Of Epoch Done: 526/1000\n",
      "Number Of Epoch Done: 527/1000\n",
      "Number Of Epoch Done: 528/1000\n",
      "Number Of Epoch Done: 529/1000\n",
      "Number Of Epoch Done: 530/1000\n",
      "Number Of Epoch Done: 531/1000\n",
      "Number Of Epoch Done: 532/1000\n",
      "Number Of Epoch Done: 533/1000\n",
      "Number Of Epoch Done: 534/1000\n",
      "Number Of Epoch Done: 535/1000\n",
      "Number Of Epoch Done: 536/1000\n",
      "Number Of Epoch Done: 537/1000\n",
      "Number Of Epoch Done: 538/1000\n",
      "Number Of Epoch Done: 539/1000\n",
      "Number Of Epoch Done: 540/1000\n",
      "Number Of Epoch Done: 541/1000\n",
      "Number Of Epoch Done: 542/1000\n",
      "Number Of Epoch Done: 543/1000\n",
      "Number Of Epoch Done: 544/1000\n",
      "Number Of Epoch Done: 545/1000\n",
      "Number Of Epoch Done: 546/1000\n",
      "Number Of Epoch Done: 547/1000\n",
      "Number Of Epoch Done: 548/1000\n",
      "Number Of Epoch Done: 549/1000\n",
      "Number Of Epoch Done: 550/1000\n",
      "Number Of Epoch Done: 551/1000\n",
      "Number Of Epoch Done: 552/1000\n",
      "Number Of Epoch Done: 553/1000\n",
      "Number Of Epoch Done: 554/1000\n",
      "Number Of Epoch Done: 555/1000\n",
      "Number Of Epoch Done: 556/1000\n",
      "Number Of Epoch Done: 557/1000\n",
      "Number Of Epoch Done: 558/1000\n",
      "Number Of Epoch Done: 559/1000\n",
      "Number Of Epoch Done: 560/1000\n",
      "Number Of Epoch Done: 561/1000\n",
      "Number Of Epoch Done: 562/1000\n",
      "Number Of Epoch Done: 563/1000\n",
      "Number Of Epoch Done: 564/1000\n",
      "Number Of Epoch Done: 565/1000\n",
      "Number Of Epoch Done: 566/1000\n",
      "Number Of Epoch Done: 567/1000\n",
      "Number Of Epoch Done: 568/1000\n",
      "Number Of Epoch Done: 569/1000\n",
      "Number Of Epoch Done: 570/1000\n",
      "Number Of Epoch Done: 571/1000\n",
      "Number Of Epoch Done: 572/1000\n",
      "Number Of Epoch Done: 573/1000\n",
      "Number Of Epoch Done: 574/1000\n",
      "Number Of Epoch Done: 575/1000\n",
      "Number Of Epoch Done: 576/1000\n",
      "Number Of Epoch Done: 577/1000\n",
      "Number Of Epoch Done: 578/1000\n",
      "Number Of Epoch Done: 579/1000\n",
      "Number Of Epoch Done: 580/1000\n",
      "Number Of Epoch Done: 581/1000\n",
      "Number Of Epoch Done: 582/1000\n",
      "Number Of Epoch Done: 583/1000\n",
      "Number Of Epoch Done: 584/1000\n",
      "Number Of Epoch Done: 585/1000\n",
      "Number Of Epoch Done: 586/1000\n",
      "Number Of Epoch Done: 587/1000\n",
      "Number Of Epoch Done: 588/1000\n",
      "Number Of Epoch Done: 589/1000\n",
      "Number Of Epoch Done: 590/1000\n",
      "Number Of Epoch Done: 591/1000\n",
      "Number Of Epoch Done: 592/1000\n",
      "Number Of Epoch Done: 593/1000\n",
      "Number Of Epoch Done: 594/1000\n",
      "Number Of Epoch Done: 595/1000\n",
      "Number Of Epoch Done: 596/1000\n",
      "Number Of Epoch Done: 597/1000\n",
      "Number Of Epoch Done: 598/1000\n",
      "Number Of Epoch Done: 599/1000\n",
      "Number Of Epoch Done: 600/1000\n",
      "Number Of Epoch Done: 601/1000\n",
      "Number Of Epoch Done: 602/1000\n",
      "Number Of Epoch Done: 603/1000\n",
      "Number Of Epoch Done: 604/1000\n",
      "Number Of Epoch Done: 605/1000\n",
      "Number Of Epoch Done: 606/1000\n",
      "Number Of Epoch Done: 607/1000\n",
      "Number Of Epoch Done: 608/1000\n",
      "Number Of Epoch Done: 609/1000\n",
      "Number Of Epoch Done: 610/1000\n",
      "Number Of Epoch Done: 611/1000\n",
      "Number Of Epoch Done: 612/1000\n",
      "Number Of Epoch Done: 613/1000\n",
      "Number Of Epoch Done: 614/1000\n",
      "Number Of Epoch Done: 615/1000\n",
      "Number Of Epoch Done: 616/1000\n",
      "Number Of Epoch Done: 617/1000\n",
      "Number Of Epoch Done: 618/1000\n",
      "Number Of Epoch Done: 619/1000\n",
      "Number Of Epoch Done: 620/1000\n",
      "Number Of Epoch Done: 621/1000\n",
      "Number Of Epoch Done: 622/1000\n",
      "Number Of Epoch Done: 623/1000\n",
      "Number Of Epoch Done: 624/1000\n",
      "Number Of Epoch Done: 625/1000\n",
      "Number Of Epoch Done: 626/1000\n",
      "Number Of Epoch Done: 627/1000\n",
      "Number Of Epoch Done: 628/1000\n",
      "Number Of Epoch Done: 629/1000\n",
      "Number Of Epoch Done: 630/1000\n",
      "Number Of Epoch Done: 631/1000\n",
      "Number Of Epoch Done: 632/1000\n",
      "Number Of Epoch Done: 633/1000\n",
      "Number Of Epoch Done: 634/1000\n",
      "Number Of Epoch Done: 635/1000\n",
      "Number Of Epoch Done: 636/1000\n",
      "Number Of Epoch Done: 637/1000\n",
      "Number Of Epoch Done: 638/1000\n",
      "Number Of Epoch Done: 639/1000\n",
      "Number Of Epoch Done: 640/1000\n",
      "Number Of Epoch Done: 641/1000\n",
      "Number Of Epoch Done: 642/1000\n",
      "Number Of Epoch Done: 643/1000\n",
      "Number Of Epoch Done: 644/1000\n",
      "Number Of Epoch Done: 645/1000\n",
      "Number Of Epoch Done: 646/1000\n",
      "Number Of Epoch Done: 647/1000\n",
      "Number Of Epoch Done: 648/1000\n",
      "Number Of Epoch Done: 649/1000\n",
      "Number Of Epoch Done: 650/1000\n",
      "Number Of Epoch Done: 651/1000\n",
      "Number Of Epoch Done: 652/1000\n",
      "Number Of Epoch Done: 653/1000\n",
      "Number Of Epoch Done: 654/1000\n",
      "Number Of Epoch Done: 655/1000\n",
      "Number Of Epoch Done: 656/1000\n",
      "Number Of Epoch Done: 657/1000\n",
      "Number Of Epoch Done: 658/1000\n",
      "Number Of Epoch Done: 659/1000\n",
      "Number Of Epoch Done: 660/1000\n",
      "Number Of Epoch Done: 661/1000\n",
      "Number Of Epoch Done: 662/1000\n",
      "Number Of Epoch Done: 663/1000\n",
      "Number Of Epoch Done: 664/1000\n",
      "Number Of Epoch Done: 665/1000\n",
      "Number Of Epoch Done: 666/1000\n",
      "Number Of Epoch Done: 667/1000\n",
      "Number Of Epoch Done: 668/1000\n",
      "Number Of Epoch Done: 669/1000\n",
      "Number Of Epoch Done: 670/1000\n",
      "Number Of Epoch Done: 671/1000\n",
      "Number Of Epoch Done: 672/1000\n",
      "Number Of Epoch Done: 673/1000\n",
      "Number Of Epoch Done: 674/1000\n",
      "Number Of Epoch Done: 675/1000\n",
      "Number Of Epoch Done: 676/1000\n",
      "Number Of Epoch Done: 677/1000\n",
      "Number Of Epoch Done: 678/1000\n",
      "Number Of Epoch Done: 679/1000\n",
      "Number Of Epoch Done: 680/1000\n",
      "Number Of Epoch Done: 681/1000\n",
      "Number Of Epoch Done: 682/1000\n",
      "Number Of Epoch Done: 683/1000\n",
      "Number Of Epoch Done: 684/1000\n",
      "Number Of Epoch Done: 685/1000\n",
      "Number Of Epoch Done: 686/1000\n",
      "Number Of Epoch Done: 687/1000\n",
      "Number Of Epoch Done: 688/1000\n",
      "Number Of Epoch Done: 689/1000\n",
      "Number Of Epoch Done: 690/1000\n",
      "Number Of Epoch Done: 691/1000\n",
      "Number Of Epoch Done: 692/1000\n",
      "Number Of Epoch Done: 693/1000\n",
      "Number Of Epoch Done: 694/1000\n",
      "Number Of Epoch Done: 695/1000\n",
      "Number Of Epoch Done: 696/1000\n",
      "Number Of Epoch Done: 697/1000\n",
      "Number Of Epoch Done: 698/1000\n",
      "Number Of Epoch Done: 699/1000\n",
      "Number Of Epoch Done: 700/1000\n",
      "Number Of Epoch Done: 701/1000\n",
      "Number Of Epoch Done: 702/1000\n",
      "Number Of Epoch Done: 703/1000\n",
      "Number Of Epoch Done: 704/1000\n",
      "Number Of Epoch Done: 705/1000\n",
      "Number Of Epoch Done: 706/1000\n",
      "Number Of Epoch Done: 707/1000\n",
      "Number Of Epoch Done: 708/1000\n",
      "Number Of Epoch Done: 709/1000\n",
      "Number Of Epoch Done: 710/1000\n",
      "Number Of Epoch Done: 711/1000\n",
      "Number Of Epoch Done: 712/1000\n",
      "Number Of Epoch Done: 713/1000\n",
      "Number Of Epoch Done: 714/1000\n",
      "Number Of Epoch Done: 715/1000\n",
      "Number Of Epoch Done: 716/1000\n",
      "Number Of Epoch Done: 717/1000\n",
      "Number Of Epoch Done: 718/1000\n",
      "Number Of Epoch Done: 719/1000\n",
      "Number Of Epoch Done: 720/1000\n",
      "Number Of Epoch Done: 721/1000\n",
      "Number Of Epoch Done: 722/1000\n",
      "Number Of Epoch Done: 723/1000\n",
      "Number Of Epoch Done: 724/1000\n",
      "Number Of Epoch Done: 725/1000\n",
      "Number Of Epoch Done: 726/1000\n",
      "Number Of Epoch Done: 727/1000\n",
      "Number Of Epoch Done: 728/1000\n",
      "Number Of Epoch Done: 729/1000\n",
      "Number Of Epoch Done: 730/1000\n",
      "Number Of Epoch Done: 731/1000\n",
      "Number Of Epoch Done: 732/1000\n",
      "Number Of Epoch Done: 733/1000\n",
      "Number Of Epoch Done: 734/1000\n",
      "Number Of Epoch Done: 735/1000\n",
      "Number Of Epoch Done: 736/1000\n",
      "Number Of Epoch Done: 737/1000\n",
      "Number Of Epoch Done: 738/1000\n",
      "Number Of Epoch Done: 739/1000\n",
      "Number Of Epoch Done: 740/1000\n",
      "Number Of Epoch Done: 741/1000\n",
      "Number Of Epoch Done: 742/1000\n",
      "Number Of Epoch Done: 743/1000\n",
      "Number Of Epoch Done: 744/1000\n",
      "Number Of Epoch Done: 745/1000\n",
      "Number Of Epoch Done: 746/1000\n",
      "Number Of Epoch Done: 747/1000\n",
      "Number Of Epoch Done: 748/1000\n",
      "Number Of Epoch Done: 749/1000\n",
      "Number Of Epoch Done: 750/1000\n",
      "Number Of Epoch Done: 751/1000\n",
      "Number Of Epoch Done: 752/1000\n",
      "Number Of Epoch Done: 753/1000\n",
      "Number Of Epoch Done: 754/1000\n",
      "Number Of Epoch Done: 755/1000\n",
      "Number Of Epoch Done: 756/1000\n",
      "Number Of Epoch Done: 757/1000\n",
      "Number Of Epoch Done: 758/1000\n",
      "Number Of Epoch Done: 759/1000\n",
      "Number Of Epoch Done: 760/1000\n",
      "Number Of Epoch Done: 761/1000\n",
      "Number Of Epoch Done: 762/1000\n",
      "Number Of Epoch Done: 763/1000\n",
      "Number Of Epoch Done: 764/1000\n",
      "Number Of Epoch Done: 765/1000\n",
      "Number Of Epoch Done: 766/1000\n",
      "Number Of Epoch Done: 767/1000\n",
      "Number Of Epoch Done: 768/1000\n",
      "Number Of Epoch Done: 769/1000\n",
      "Number Of Epoch Done: 770/1000\n",
      "Number Of Epoch Done: 771/1000\n",
      "Number Of Epoch Done: 772/1000\n",
      "Number Of Epoch Done: 773/1000\n",
      "Number Of Epoch Done: 774/1000\n",
      "Number Of Epoch Done: 775/1000\n",
      "Number Of Epoch Done: 776/1000\n",
      "Number Of Epoch Done: 777/1000\n",
      "Number Of Epoch Done: 778/1000\n",
      "Number Of Epoch Done: 779/1000\n",
      "Number Of Epoch Done: 780/1000\n",
      "Number Of Epoch Done: 781/1000\n",
      "Number Of Epoch Done: 782/1000\n",
      "Number Of Epoch Done: 783/1000\n",
      "Number Of Epoch Done: 784/1000\n",
      "Number Of Epoch Done: 785/1000\n",
      "Number Of Epoch Done: 786/1000\n",
      "Number Of Epoch Done: 787/1000\n",
      "Number Of Epoch Done: 788/1000\n",
      "Number Of Epoch Done: 789/1000\n",
      "Number Of Epoch Done: 790/1000\n",
      "Number Of Epoch Done: 791/1000\n",
      "Number Of Epoch Done: 792/1000\n",
      "Number Of Epoch Done: 793/1000\n",
      "Number Of Epoch Done: 794/1000\n",
      "Number Of Epoch Done: 795/1000\n",
      "Number Of Epoch Done: 796/1000\n",
      "Number Of Epoch Done: 797/1000\n",
      "Number Of Epoch Done: 798/1000\n",
      "Number Of Epoch Done: 799/1000\n",
      "Number Of Epoch Done: 800/1000\n",
      "Number Of Epoch Done: 801/1000\n",
      "Number Of Epoch Done: 802/1000\n",
      "Number Of Epoch Done: 803/1000\n",
      "Number Of Epoch Done: 804/1000\n",
      "Number Of Epoch Done: 805/1000\n",
      "Number Of Epoch Done: 806/1000\n",
      "Number Of Epoch Done: 807/1000\n",
      "Number Of Epoch Done: 808/1000\n",
      "Number Of Epoch Done: 809/1000\n",
      "Number Of Epoch Done: 810/1000\n",
      "Number Of Epoch Done: 811/1000\n",
      "Number Of Epoch Done: 812/1000\n",
      "Number Of Epoch Done: 813/1000\n",
      "Number Of Epoch Done: 814/1000\n",
      "Number Of Epoch Done: 815/1000\n",
      "Number Of Epoch Done: 816/1000\n",
      "Number Of Epoch Done: 817/1000\n",
      "Number Of Epoch Done: 818/1000\n",
      "Number Of Epoch Done: 819/1000\n",
      "Number Of Epoch Done: 820/1000\n",
      "Number Of Epoch Done: 821/1000\n",
      "Number Of Epoch Done: 822/1000\n",
      "Number Of Epoch Done: 823/1000\n",
      "Number Of Epoch Done: 824/1000\n",
      "Number Of Epoch Done: 825/1000\n",
      "Number Of Epoch Done: 826/1000\n",
      "Number Of Epoch Done: 827/1000\n",
      "Number Of Epoch Done: 828/1000\n",
      "Number Of Epoch Done: 829/1000\n",
      "Number Of Epoch Done: 830/1000\n",
      "Number Of Epoch Done: 831/1000\n",
      "Number Of Epoch Done: 832/1000\n",
      "Number Of Epoch Done: 833/1000\n",
      "Number Of Epoch Done: 834/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/tkinter/__init__.py\", line 1971, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/tkinter/__init__.py\", line 865, in callit\n",
      "    func(*args)\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/backends/_backend_tk.py\", line 271, in idle_draw\n",
      "    self.draw()\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/backends/backend_tkagg.py\", line 10, in draw\n",
      "    super().draw()\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py\", line 387, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/artist.py\", line 95, in draw_wrapper\n",
      "    result = draw(artist, renderer, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/figure.py\", line 3162, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/axes/_base.py\", line 3137, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/image.py\", line 653, in draw\n",
      "    im, l, b, trans = self.make_image(\n",
      "                      ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/image.py\", line 952, in make_image\n",
      "    return self._make_image(self._A, bbox, transformed_bbox, clip,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/someone/.local/lib/python3.12/site-packages/matplotlib/image.py\", line 581, in _make_image\n",
      "    alpha_channel.astype(np.float32) * out_alpha * alpha)\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Epoch Done: 835/1000\n",
      "Number Of Epoch Done: 836/1000\n",
      "Number Of Epoch Done: 837/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 45\u001b[0m\n\u001b[1;32m     40\u001b[0m trans_img\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[1;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 45\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreconstructed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mauto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m, in \u001b[0;36mCoverArtsDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprepareTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[68], line 2\u001b[0m, in \u001b[0;36mprepareTensor\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepareTensor\u001b[39m(path):\n\u001b[0;32m----> 2\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m99\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m99\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mToTensor()(img)\n\u001b[1;32m      4\u001b[0m     img\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/PIL/Image.py:2365\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2353\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2354\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2355\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2356\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2357\u001b[0m         )\n\u001b[1;32m   2358\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2359\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2360\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2361\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2362\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2363\u001b[0m         )\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "raw_img = fig.add_axes([0, 0.5, 0.5 - 0.02, 0.5 - 0.02])\n",
    "trans_img = fig.add_axes([0.5, 0.5, 0.5 - 0.02, 0.5 - 0.02])\n",
    "\n",
    "loss_ax = fig.add_axes([0, 0, 1 - 0.02, 0.5 - 0.02])\n",
    "\n",
    "raw_img.axis(\"off\")\n",
    "trans_img.axis(\"off\")\n",
    "loss_ax.axis(\"off\")\n",
    "\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "print(f\"Using Device: {device}\")\n",
    "auto = ConvAutoencoder().to(device)\n",
    "\n",
    "try:\n",
    "    auto.load_state_dict(helper_fetch_localmodel())\n",
    "except Exception:\n",
    "    print(\"[ERROR]: Cant Load Saved Model\")\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(auto.parameters(), lr=0.001)\n",
    "NUM_EPOCHS = 1000\n",
    "BATCH_SIZE = 40\n",
    "loss_ax.set_xlim(left=0, right=NUM_EPOCHS)\n",
    "dataset = CoverArtsDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    sample_path = random.choice(image_paths)\n",
    "    sample_data = prepareTensor(sample_path).unsqueeze(1)\n",
    "    sample = auto(sample_data.to(device))\n",
    "\n",
    "    \n",
    "    img = toimg(sample.to(\"cpu\"))\n",
    "\n",
    "    raw_img.imshow(np.uint8((sample_data.view(99, 99) * 255).detach().numpy()))\n",
    "    trans_img.imshow(img)\n",
    "\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    for data in dataloader:\n",
    "        reconstructed = auto(data.to(device)).to(device)\n",
    "        original = data.to(device)\n",
    "        loss = criterion(reconstructed, original).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    loss_ax.plot(epoch, loss.to(\"cpu\").item(), \"ro--\")\n",
    "    fig.show()\n",
    "    fig.canvas.flush_events()\n",
    "    \n",
    "    \n",
    "    print(f\"Number Of Epoch Done: {epoch}/{NUM_EPOCHS}\")\n",
    "    \n",
    "torch.save(auto.state_dict(), f\"autoencoder_{epoch}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1433eddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8171/2531894511.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(get_model_state_dict(), map_location=torch.device(device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder.0.weight',\n",
       "              tensor([[[[ 0.1221,  0.0052,  0.1185],\n",
       "                        [ 0.1725,  0.1164, -0.1500],\n",
       "                        [-0.1629, -0.3617,  0.1209]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1544, -0.1167, -0.2479],\n",
       "                        [-0.0233, -0.1701, -0.1971],\n",
       "                        [ 0.0969, -0.1937,  0.1468]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4684, -0.3855,  0.1657],\n",
       "                        [-0.1350,  0.1726, -0.2095],\n",
       "                        [ 0.0098, -0.0027, -0.4146]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2264,  0.2527,  0.3870],\n",
       "                        [ 0.2314,  0.2646,  0.2160],\n",
       "                        [ 0.1816,  0.2731,  0.3685]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.6721, -0.5819, -0.6717],\n",
       "                        [ 0.2118,  0.1085, -0.1476],\n",
       "                        [-0.0893, -0.2227, -0.3815]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2568, -0.0054, -0.0802],\n",
       "                        [ 0.0102, -0.1310, -0.0215],\n",
       "                        [-0.4782,  0.1746,  0.1130]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.5956,  0.3062, -0.6167],\n",
       "                        [-0.3181,  0.2057, -0.3017],\n",
       "                        [-0.7763, -0.2242, -0.6743]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0747,  0.1158, -0.0954],\n",
       "                        [-0.0309, -0.3202, -0.2944],\n",
       "                        [-0.1710,  0.2248, -0.1682]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1100,  0.1191, -0.4159],\n",
       "                        [ 0.0650, -0.6018, -0.2810],\n",
       "                        [-0.4781, -0.1647, -0.1619]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0293,  0.0292, -0.0927],\n",
       "                        [-0.0928, -0.4451, -0.0035],\n",
       "                        [-0.4917, -0.2369,  0.0218]]]])),\n",
       "             ('encoder.0.bias',\n",
       "              tensor([-0.4282, -0.1463, -0.1636, -0.8289, -0.2995, -0.3923,  0.5004, -0.0934,\n",
       "                      -0.2961, -0.4252])),\n",
       "             ('encoder.3.weight',\n",
       "              tensor([[[[ 7.7975e-02, -1.4798e-02, -1.1828e-01],\n",
       "                        [-7.6353e-02,  2.6342e-02,  5.1686e-02],\n",
       "                        [-1.1894e-01, -7.4619e-02,  6.6744e-02]],\n",
       "              \n",
       "                       [[-1.2558e-01, -1.0138e-01, -9.8835e-02],\n",
       "                        [-8.5911e-02,  4.0887e-03,  1.6193e-02],\n",
       "                        [-4.9288e-03, -2.3383e-02, -1.3139e-01]],\n",
       "              \n",
       "                       [[-1.2782e-02,  1.6551e-02, -4.5792e-02],\n",
       "                        [ 3.5912e-03,  6.7628e-02, -5.4807e-02],\n",
       "                        [-7.4866e-02, -9.8143e-03,  7.3269e-02]],\n",
       "              \n",
       "                       [[-8.7339e-01, -8.4319e-01, -1.0931e+00],\n",
       "                        [ 7.3661e-01,  5.1314e-01,  8.3322e-02],\n",
       "                        [-9.5319e-02, -6.0805e-02, -3.3847e-01]],\n",
       "              \n",
       "                       [[-3.9647e-02, -6.4041e-02,  3.1779e-01],\n",
       "                        [-2.0154e-01,  7.4607e-01,  9.8800e-01],\n",
       "                        [-8.5748e-02, -1.3677e-01, -2.2738e-01]],\n",
       "              \n",
       "                       [[ 1.5385e-02, -4.0374e-02, -1.5361e-02],\n",
       "                        [-8.7518e-02,  4.1122e-04, -4.2393e-02],\n",
       "                        [-1.0302e-01, -8.5029e-02, -6.8374e-02]],\n",
       "              \n",
       "                       [[-2.2895e+00, -1.0301e+00, -8.8356e-01],\n",
       "                        [-1.1729e+00, -3.8204e-01,  2.6044e-01],\n",
       "                        [-1.1914e-01,  5.6239e-01, -1.2449e-01]],\n",
       "              \n",
       "                       [[-6.4625e-02, -2.7456e-02,  3.8135e-03],\n",
       "                        [-2.4063e-02, -1.1459e-01, -1.1744e-01],\n",
       "                        [ 9.9572e-03, -7.6999e-02,  2.0425e-02]],\n",
       "              \n",
       "                       [[-2.0953e-02,  3.9081e-04,  7.8978e-02],\n",
       "                        [-5.7661e-03,  4.9363e-02, -8.4304e-02],\n",
       "                        [-3.1228e-02, -1.4311e-01, -1.3530e-01]],\n",
       "              \n",
       "                       [[-3.3551e-02, -1.0881e-01, -7.2053e-02],\n",
       "                        [ 2.4809e-02,  3.1593e-02, -4.1814e-02],\n",
       "                        [ 4.6081e-02, -1.7915e-02, -2.3873e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0316e-02,  1.7958e-02, -3.3178e-02],\n",
       "                        [ 2.0228e-02, -8.9025e-02,  9.4328e-02],\n",
       "                        [-6.2738e-02, -5.5174e-02,  7.0895e-02]],\n",
       "              \n",
       "                       [[-5.6953e-02,  1.2056e-01, -7.5839e-02],\n",
       "                        [-5.1269e-02, -6.9706e-02,  6.9652e-02],\n",
       "                        [-3.5041e-03,  9.2177e-02,  3.0139e-01]],\n",
       "              \n",
       "                       [[-4.7663e-02, -1.9138e-02,  1.9921e-02],\n",
       "                        [ 2.0481e-03, -8.2048e-02, -1.4919e-01],\n",
       "                        [-3.9271e-02,  9.7700e-03, -6.8128e-02]],\n",
       "              \n",
       "                       [[ 3.0464e-01,  2.2553e-01,  3.3978e-01],\n",
       "                        [ 1.8275e-01,  1.1770e-01,  1.3674e-01],\n",
       "                        [ 1.7940e-01,  2.2988e-01,  2.9232e-01]],\n",
       "              \n",
       "                       [[ 7.7129e-01,  5.4742e-01, -1.6875e-01],\n",
       "                        [ 3.9709e-02,  1.1842e-01,  2.1158e-01],\n",
       "                        [ 2.5789e-01,  1.0775e-01,  1.2095e-03]],\n",
       "              \n",
       "                       [[ 3.9503e-02,  6.9041e-02, -6.0292e-02],\n",
       "                        [-9.9656e-03,  4.2099e-02, -3.7603e-02],\n",
       "                        [ 9.9289e-02,  6.0522e-02, -9.9643e-02]],\n",
       "              \n",
       "                       [[-3.3473e-01, -7.9882e-01, -3.5860e-01],\n",
       "                        [ 1.4710e-01, -6.6074e-02, -2.8252e-01],\n",
       "                        [ 1.2596e-01, -1.9167e-01,  1.5642e-02]],\n",
       "              \n",
       "                       [[-8.6714e-03,  1.5794e-02,  2.8628e-02],\n",
       "                        [-8.6678e-02, -2.9642e-02, -9.5379e-02],\n",
       "                        [-3.4977e-03,  3.9157e-02,  2.0139e-02]],\n",
       "              \n",
       "                       [[ 5.4909e-03,  1.0949e-01,  2.2860e-02],\n",
       "                        [ 1.1376e-01, -7.1633e-02,  1.1183e-01],\n",
       "                        [ 2.6764e-01,  1.4373e-01,  2.3499e-01]],\n",
       "              \n",
       "                       [[ 4.9252e-02, -8.8046e-02, -1.0580e-01],\n",
       "                        [ 5.4505e-02, -1.7454e-01,  1.7267e-02],\n",
       "                        [-2.0021e-02, -1.9240e-02, -7.0198e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4198e-01,  7.9875e-02,  1.1193e-01],\n",
       "                        [ 9.3413e-02,  4.3830e-02,  4.8529e-03],\n",
       "                        [ 9.8995e-02,  2.8705e-02,  9.6395e-02]],\n",
       "              \n",
       "                       [[-6.6064e-02, -8.1926e-02, -1.3618e-01],\n",
       "                        [-1.9833e-01, -2.0540e-01, -1.5557e-02],\n",
       "                        [ 1.9122e-02,  4.5269e-02, -2.2371e-02]],\n",
       "              \n",
       "                       [[ 1.6305e-01,  6.7978e-02, -9.5454e-02],\n",
       "                        [ 2.1998e-01,  2.6893e-02, -5.0831e-02],\n",
       "                        [ 1.7965e-01, -7.0696e-02, -2.1021e-01]],\n",
       "              \n",
       "                       [[ 1.2580e-02, -3.9068e-04,  3.9861e-02],\n",
       "                        [-1.6543e-01, -4.9466e-01, -1.8829e-01],\n",
       "                        [-4.2976e-02, -1.3604e-01,  2.5857e-02]],\n",
       "              \n",
       "                       [[ 4.9187e-01, -2.2050e-01, -2.7047e-01],\n",
       "                        [ 2.5269e-01,  1.2675e-01, -1.7248e-01],\n",
       "                        [ 2.3447e-01, -1.7233e-01, -4.3792e-01]],\n",
       "              \n",
       "                       [[ 4.9854e-02, -1.3318e-01, -3.9240e-02],\n",
       "                        [-2.8867e-02, -9.3130e-02, -8.0623e-03],\n",
       "                        [ 5.6154e-02,  5.0597e-02, -1.0159e-01]],\n",
       "              \n",
       "                       [[-5.9137e-01,  6.5292e-01, -4.5904e-01],\n",
       "                        [-3.2809e-01,  6.0380e-01, -2.3016e-01],\n",
       "                        [ 9.8173e-02,  9.9982e-01,  3.3340e-02]],\n",
       "              \n",
       "                       [[-3.2791e-02, -4.3522e-02, -1.1057e-01],\n",
       "                        [-1.0078e-02, -4.2898e-02,  2.8678e-02],\n",
       "                        [ 8.5819e-02, -2.5025e-02, -7.3931e-02]],\n",
       "              \n",
       "                       [[ 3.5922e-01, -1.7437e-01,  7.2554e-02],\n",
       "                        [-3.8944e-02, -1.7287e-02, -1.8680e-02],\n",
       "                        [-8.9146e-03,  5.6906e-02, -3.2387e-01]],\n",
       "              \n",
       "                       [[-1.7482e-01, -2.7742e-01, -1.0955e-01],\n",
       "                        [-7.4258e-02, -2.9536e-01,  2.5413e-03],\n",
       "                        [-2.3035e-01, -2.7891e-01, -1.7292e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.6634e-02,  7.9644e-02,  3.4239e-02],\n",
       "                        [ 5.5639e-02,  1.7104e-01,  2.9305e-02],\n",
       "                        [ 4.7157e-02,  9.5750e-02, -5.9648e-02]],\n",
       "              \n",
       "                       [[ 1.4050e-02, -6.5860e-02, -8.0280e-02],\n",
       "                        [ 3.3355e-03, -1.0347e-01, -8.5214e-02],\n",
       "                        [ 1.5668e-02,  2.9919e-02,  4.3576e-02]],\n",
       "              \n",
       "                       [[ 2.4295e-02, -9.2333e-02, -5.7474e-02],\n",
       "                        [-3.3124e-02,  4.2217e-02, -5.5061e-02],\n",
       "                        [-1.0935e-01,  6.2208e-02, -2.4989e-02]],\n",
       "              \n",
       "                       [[-1.9663e-01, -1.2879e-01, -2.0327e-01],\n",
       "                        [-2.6076e-01, -3.1590e-01, -2.5434e-01],\n",
       "                        [-3.0679e-02, -4.4847e-03, -4.9991e-02]],\n",
       "              \n",
       "                       [[ 3.5958e-01,  3.5145e-01,  3.7720e-01],\n",
       "                        [ 4.2956e-01,  2.5652e-01,  1.4650e-01],\n",
       "                        [ 8.5838e-01,  6.5632e-01,  3.6995e-01]],\n",
       "              \n",
       "                       [[ 2.9025e-01, -1.7185e-02,  4.9356e-02],\n",
       "                        [ 1.9347e-01,  9.2717e-02, -7.9122e-02],\n",
       "                        [ 1.1533e-01,  5.0999e-02,  9.6424e-02]],\n",
       "              \n",
       "                       [[-4.2531e-02,  9.3857e-03, -4.9343e-02],\n",
       "                        [ 1.4982e-01,  1.5676e-01,  6.2867e-02],\n",
       "                        [-1.4729e-01,  1.0624e-02, -1.5971e-01]],\n",
       "              \n",
       "                       [[-7.8151e-02,  8.2740e-02,  1.3077e-03],\n",
       "                        [-8.0249e-02, -3.1928e-02, -6.0329e-02],\n",
       "                        [-7.7352e-02, -7.5002e-02, -6.9476e-02]],\n",
       "              \n",
       "                       [[-2.8483e-02, -1.2798e-01, -9.8759e-02],\n",
       "                        [-7.4372e-02, -2.9015e-02, -8.1117e-02],\n",
       "                        [ 5.2891e-02, -1.4756e-02, -1.9416e-02]],\n",
       "              \n",
       "                       [[ 2.7985e-05, -1.3293e-01, -1.3664e-01],\n",
       "                        [-7.8259e-02, -1.8451e-01, -5.0392e-02],\n",
       "                        [-7.3656e-02, -2.5343e-01, -2.7299e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.1200e-02,  9.7488e-02, -5.6049e-02],\n",
       "                        [-1.0718e-01, -9.7867e-02,  1.6336e-02],\n",
       "                        [-5.4290e-02,  7.2950e-03,  6.4511e-02]],\n",
       "              \n",
       "                       [[-9.7139e-02,  1.0050e-01, -2.0783e-02],\n",
       "                        [-9.3333e-02, -5.1070e-02, -5.8418e-02],\n",
       "                        [-3.8360e-02, -7.1942e-02, -3.1133e-02]],\n",
       "              \n",
       "                       [[-8.2107e-02,  4.8831e-02, -1.0366e-01],\n",
       "                        [-1.1060e-01,  5.4260e-02, -7.6041e-02],\n",
       "                        [ 2.3495e-02, -8.8864e-02, -1.2597e-01]],\n",
       "              \n",
       "                       [[ 2.3163e-02,  1.5076e-02, -8.7636e-02],\n",
       "                        [-7.9640e-03, -9.6197e-02,  4.8464e-02],\n",
       "                        [-1.4879e-01,  2.9057e-02, -9.5589e-02]],\n",
       "              \n",
       "                       [[-1.1724e-01, -6.3920e-02, -1.4961e-02],\n",
       "                        [-8.9442e-02, -1.6021e-01, -1.0021e-01],\n",
       "                        [-7.1917e-02, -7.6989e-02, -1.0002e-01]],\n",
       "              \n",
       "                       [[-4.8592e-02, -5.9497e-02, -6.7622e-02],\n",
       "                        [ 4.1836e-02, -3.5084e-02, -4.3954e-02],\n",
       "                        [-4.4947e-02,  6.4637e-02, -1.1945e-01]],\n",
       "              \n",
       "                       [[ 9.6025e-02,  8.7671e-03, -8.7584e-02],\n",
       "                        [ 7.5455e-02,  1.6709e-03,  1.1681e-02],\n",
       "                        [ 1.9622e-02, -7.3552e-02,  7.5396e-02]],\n",
       "              \n",
       "                       [[ 1.6614e-02,  4.3858e-02, -8.5817e-02],\n",
       "                        [ 3.7265e-02,  2.1079e-02, -1.1158e-01],\n",
       "                        [ 1.4883e-02, -1.6702e-02, -1.9000e-02]],\n",
       "              \n",
       "                       [[-7.7407e-02, -8.4036e-02, -9.1924e-02],\n",
       "                        [ 4.0565e-02, -1.0190e-01, -3.4165e-02],\n",
       "                        [-8.2307e-02, -1.3853e-01, -3.1923e-02]],\n",
       "              \n",
       "                       [[ 2.9596e-02, -1.0417e-01,  5.5536e-02],\n",
       "                        [-1.1891e-01, -8.9090e-02,  4.9435e-02],\n",
       "                        [ 3.9753e-02, -8.4214e-02,  1.9481e-02]]]])),\n",
       "             ('encoder.3.bias',\n",
       "              tensor([-0.2413, -0.0645,  0.6620, -0.2929, -0.1985])),\n",
       "             ('encoder.6.weight',\n",
       "              tensor([[[[ 1.0705e-02,  3.6083e-02,  3.9457e-02],\n",
       "                        [ 9.0447e-02,  1.1715e-01,  8.1950e-02],\n",
       "                        [ 7.3885e-02, -3.0050e-02,  1.1103e-01]],\n",
       "              \n",
       "                       [[ 4.6663e-02,  5.6127e-03, -8.0822e-02],\n",
       "                        [-7.5353e-02, -2.8095e-02, -1.5128e-01],\n",
       "                        [ 6.1516e-02,  5.4014e-03,  3.9734e-02]],\n",
       "              \n",
       "                       [[-3.7836e-02, -2.3236e-01, -2.5474e-01],\n",
       "                        [-2.0398e-01, -3.9693e-01, -3.5176e-01],\n",
       "                        [-1.6409e-01, -1.1220e-01, -1.2031e-01]],\n",
       "              \n",
       "                       [[ 5.7679e-02, -1.3607e-01, -1.0893e-02],\n",
       "                        [ 6.1941e-02, -1.5524e-01, -8.4313e-02],\n",
       "                        [-1.7007e-01, -8.3787e-02, -1.6893e-01]],\n",
       "              \n",
       "                       [[ 5.7379e-02, -1.2331e-01, -1.1744e-01],\n",
       "                        [-5.5325e-02, -1.3568e-01, -8.2861e-02],\n",
       "                        [ 9.8411e-02,  8.4469e-03, -3.9865e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.9010e-01, -8.2670e-01, -6.6240e-02],\n",
       "                        [-2.2190e-01,  7.2566e-02,  8.8218e-01],\n",
       "                        [ 5.3450e-01,  6.8899e-01,  1.9219e-01]],\n",
       "              \n",
       "                       [[-6.3411e-01, -2.5119e-01, -5.7104e-01],\n",
       "                        [-2.7834e-02,  6.8393e-01, -3.5949e-01],\n",
       "                        [-4.1573e-01, -4.2116e-02, -3.1436e-01]],\n",
       "              \n",
       "                       [[ 3.4244e-01,  1.0821e-01,  1.7689e-01],\n",
       "                        [ 2.1085e-01,  1.8578e-01,  3.4185e-01],\n",
       "                        [ 5.5341e-01,  1.6006e-01,  3.4298e-01]],\n",
       "              \n",
       "                       [[ 6.2887e-02,  1.6954e-01, -7.4643e-02],\n",
       "                        [ 1.9345e-01,  1.6625e-01,  1.7188e-01],\n",
       "                        [-2.0269e-01, -2.0527e-01, -1.5063e-01]],\n",
       "              \n",
       "                       [[-3.6947e-02,  9.1524e-02, -8.1690e-02],\n",
       "                        [-2.4801e-02,  1.2890e-02, -6.8963e-02],\n",
       "                        [ 6.4656e-02,  1.7555e-02, -8.5901e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.8904e-02,  1.1311e-01,  8.4595e-02],\n",
       "                        [ 1.0172e-01,  3.1534e-02,  8.4634e-02],\n",
       "                        [ 3.3372e-02, -8.4531e-02, -4.5726e-02]],\n",
       "              \n",
       "                       [[-1.3948e-01, -9.6441e-02, -7.0540e-02],\n",
       "                        [ 4.4457e-02, -7.1782e-02, -7.4875e-02],\n",
       "                        [ 3.2137e-02, -7.1858e-02, -4.0513e-02]],\n",
       "              \n",
       "                       [[ 5.7822e-03, -1.1981e-01,  3.4698e-02],\n",
       "                        [-9.3622e-02, -7.8795e-03, -3.3005e-03],\n",
       "                        [ 2.7137e-02, -5.4311e-03, -1.2154e-01]],\n",
       "              \n",
       "                       [[-1.3453e-02, -5.2187e-03,  1.8934e-02],\n",
       "                        [-7.4962e-02, -1.5944e-01, -4.6042e-02],\n",
       "                        [-1.2565e-01, -6.4099e-02, -1.0615e-01]],\n",
       "              \n",
       "                       [[ 5.1760e-03, -1.3741e-01,  8.2680e-02],\n",
       "                        [-1.1392e-01,  3.2394e-02, -1.1663e-02],\n",
       "                        [ 4.1851e-02,  1.4517e-01,  6.7311e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0643e-01, -1.2032e-01, -1.6625e-01],\n",
       "                        [-8.1560e-02, -8.8156e-02, -1.7012e-01],\n",
       "                        [-3.5142e-01, -3.1117e-01,  4.6535e-01]],\n",
       "              \n",
       "                       [[-5.1160e-01, -5.4013e-01, -5.2080e-01],\n",
       "                        [-3.6468e-01, -3.5551e-01, -5.6576e-01],\n",
       "                        [-5.2715e-01, -3.1861e-01, -3.4732e-01]],\n",
       "              \n",
       "                       [[-2.0398e-01, -1.6660e-01, -1.6452e-02],\n",
       "                        [-9.7758e-02, -3.4981e-01, -2.4980e-01],\n",
       "                        [-2.7151e-01, -2.1194e-01, -1.7475e-01]],\n",
       "              \n",
       "                       [[ 1.4423e-01,  3.8596e-02,  1.0036e-01],\n",
       "                        [-9.1381e-02, -1.0874e-02, -1.1764e-01],\n",
       "                        [ 1.3768e-01, -9.3000e-02,  1.5209e-01]],\n",
       "              \n",
       "                       [[ 1.1619e-01, -9.8491e-03,  8.5061e-02],\n",
       "                        [ 1.2454e-01,  5.2965e-02, -3.8988e-02],\n",
       "                        [ 5.5920e-02,  3.9912e-02,  7.5636e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.6086e-01,  2.2357e-01,  9.1700e-01],\n",
       "                        [-5.3372e-01, -5.2629e-01,  4.9248e-01],\n",
       "                        [ 1.1771e-01,  1.4435e-01,  2.4145e-01]],\n",
       "              \n",
       "                       [[ 9.0512e-02, -3.5638e-02,  9.5334e-02],\n",
       "                        [ 7.5422e-04, -3.6612e-02,  7.5066e-02],\n",
       "                        [ 1.4415e-01,  1.3829e-01,  1.3813e-01]],\n",
       "              \n",
       "                       [[-2.4209e+00, -2.2177e+00, -1.6930e+00],\n",
       "                        [-1.1413e+00, -2.4132e+00, -9.3456e-01],\n",
       "                        [-8.3106e-01, -1.4862e+00, -1.0019e+00]],\n",
       "              \n",
       "                       [[-1.2408e-01, -1.3351e-01, -5.7482e-02],\n",
       "                        [ 1.3540e-01,  6.7800e-02,  8.4035e-02],\n",
       "                        [ 1.3608e-01,  3.9372e-02, -1.0966e-01]],\n",
       "              \n",
       "                       [[ 3.1540e-03,  9.4653e-02, -9.5485e-02],\n",
       "                        [-4.4826e-03, -8.0768e-02,  1.1742e-01],\n",
       "                        [-1.3160e-01, -1.7506e-02,  2.7465e-02]]]])),\n",
       "             ('encoder.6.bias',\n",
       "              tensor([-0.1490, -0.1341, -0.0596, -0.1266, -0.3144])),\n",
       "             ('decoder.2.weight',\n",
       "              tensor([[[[ 0.0224, -0.0104, -0.0669],\n",
       "                        [ 0.0073, -0.0729,  0.0889],\n",
       "                        [-0.1312,  0.1192, -0.0696]],\n",
       "              \n",
       "                       [[-0.0216,  0.0713,  0.0635],\n",
       "                        [-0.1042, -0.0779,  0.0869],\n",
       "                        [-0.0223,  0.0279, -0.0320]],\n",
       "              \n",
       "                       [[ 0.1369,  0.0051,  0.2323],\n",
       "                        [ 0.2666, -0.0064,  0.0069],\n",
       "                        [ 0.0226,  0.0920,  0.1903]],\n",
       "              \n",
       "                       [[ 0.1000,  0.0124, -0.0091],\n",
       "                        [-0.1101, -0.0677,  0.0344],\n",
       "                        [ 0.0566,  0.0449,  0.0812]],\n",
       "              \n",
       "                       [[ 0.0550, -0.1738,  0.1001],\n",
       "                        [-0.0618,  0.1117,  0.0668],\n",
       "                        [-0.1238, -0.1694,  0.0334]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.7151,  0.1738, -0.7461],\n",
       "                        [ 0.3820,  1.0888,  0.2851],\n",
       "                        [-0.8881,  0.3774, -0.7327]],\n",
       "              \n",
       "                       [[-0.0170,  0.2832, -0.0539],\n",
       "                        [-0.2223,  0.1376, -0.1031],\n",
       "                        [ 0.2804,  0.5300,  0.2064]],\n",
       "              \n",
       "                       [[-0.1180, -0.0709, -0.1119],\n",
       "                        [-0.0334,  0.0367,  0.0090],\n",
       "                        [-0.0351, -0.0612, -0.1501]],\n",
       "              \n",
       "                       [[-0.0306,  0.0568, -0.0434],\n",
       "                        [ 0.1064,  0.1921,  0.0867],\n",
       "                        [-0.0188,  0.0874, -0.0094]],\n",
       "              \n",
       "                       [[-0.0548,  0.5461, -0.0572],\n",
       "                        [-0.2246, -0.2943, -0.1828],\n",
       "                        [-0.3222, -0.1599, -0.1138]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1011, -0.1666, -0.1214],\n",
       "                        [ 0.0697, -0.0689, -0.1085],\n",
       "                        [ 0.0929, -0.0451,  0.0427]],\n",
       "              \n",
       "                       [[-0.1748, -0.0293,  0.0479],\n",
       "                        [-0.0048, -0.0971, -0.0775],\n",
       "                        [ 0.0375, -0.0308,  0.0065]],\n",
       "              \n",
       "                       [[-0.0147,  0.1200,  0.0206],\n",
       "                        [-0.1434, -0.0947,  0.0432],\n",
       "                        [-0.0873, -0.0153,  0.0376]],\n",
       "              \n",
       "                       [[ 0.0161, -0.0012, -0.0630],\n",
       "                        [-0.0615, -0.0807, -0.1585],\n",
       "                        [ 0.0202, -0.1713, -0.0403]],\n",
       "              \n",
       "                       [[-0.0655, -0.1660, -0.1734],\n",
       "                        [-0.1567, -0.1325,  0.0779],\n",
       "                        [-0.1698, -0.1038, -0.0734]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1027, -0.2682, -0.2872],\n",
       "                        [-0.0443, -0.3432, -0.2936],\n",
       "                        [-0.0625, -0.0793, -0.1650]],\n",
       "              \n",
       "                       [[ 0.1798, -0.2738, -0.1814],\n",
       "                        [ 0.0487, -0.3132, -0.2106],\n",
       "                        [ 0.1934, -0.1268,  0.0233]],\n",
       "              \n",
       "                       [[ 0.0281, -0.1335, -0.1095],\n",
       "                        [-0.0335,  0.0554,  0.0723],\n",
       "                        [ 0.0137, -0.0117,  0.0839]],\n",
       "              \n",
       "                       [[ 0.0015,  0.2020,  0.0413],\n",
       "                        [ 0.2229,  0.1232,  0.1353],\n",
       "                        [ 0.0803,  0.1397,  0.2544]],\n",
       "              \n",
       "                       [[-0.0525,  0.1044,  0.0618],\n",
       "                        [ 0.0096,  0.0490, -0.0114],\n",
       "                        [ 0.1147,  0.1245, -0.0070]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1197, -0.0445, -0.0157],\n",
       "                        [-0.1024,  0.0547,  0.0485],\n",
       "                        [-0.0145, -0.0349,  0.0243]],\n",
       "              \n",
       "                       [[ 0.1566, -0.0912,  0.1220],\n",
       "                        [ 0.1066, -0.5768,  0.1654],\n",
       "                        [ 0.1214, -0.4546,  0.0556]],\n",
       "              \n",
       "                       [[-0.0646, -0.2589, -0.2169],\n",
       "                        [-0.3052, -0.2690, -0.3239],\n",
       "                        [-0.0594, -0.1152, -0.2837]],\n",
       "              \n",
       "                       [[-0.0819, -0.1067, -0.0730],\n",
       "                        [-0.0580, -0.2668, -0.0516],\n",
       "                        [-0.0748, -0.0412, -0.0832]],\n",
       "              \n",
       "                       [[-0.8642,  0.0878,  0.0992],\n",
       "                        [-0.2747, -0.0868, -0.2185],\n",
       "                        [-0.2120, -0.1075, -0.2042]]]])),\n",
       "             ('decoder.2.bias',\n",
       "              tensor([-0.4390, -1.2189, -0.1936,  0.1024, -0.6627])),\n",
       "             ('decoder.5.weight',\n",
       "              tensor([[[[-1.0147e-01, -1.2364e-01, -2.4403e-02],\n",
       "                        [-1.2312e-01, -8.6780e-02,  7.6046e-03],\n",
       "                        [-8.3400e-02, -1.2174e-01, -4.6405e-02]],\n",
       "              \n",
       "                       [[ 7.3233e-02,  2.3457e-02, -1.3585e-01],\n",
       "                        [ 5.5056e-02, -8.5574e-02, -1.3261e-01],\n",
       "                        [-1.1515e-01,  4.0333e-02, -1.1755e-01]],\n",
       "              \n",
       "                       [[-9.2549e-02, -2.6805e-02, -8.9044e-02],\n",
       "                        [-7.7792e-02, -1.7102e-02, -1.2147e-01],\n",
       "                        [-1.0094e-01,  1.9562e-03,  6.5912e-02]],\n",
       "              \n",
       "                       [[-9.3462e-01, -1.1610e+00, -2.4477e+00],\n",
       "                        [-3.3630e-01, -4.4674e-01, -1.7338e+00],\n",
       "                        [-1.1528e+00, -9.3833e-01, -2.1196e+00]],\n",
       "              \n",
       "                       [[-1.2015e-01, -1.4268e-01, -6.9098e-02],\n",
       "                        [ 5.1986e-02,  1.5113e-02, -1.2792e-02],\n",
       "                        [ 4.2510e-02, -5.4721e-02, -7.4824e-02]],\n",
       "              \n",
       "                       [[-3.5993e-01, -3.2205e-01, -2.8834e-01],\n",
       "                        [-4.5588e-01, -3.9966e-01, -4.6358e-01],\n",
       "                        [-1.2445e-01, -2.3580e-01, -2.9592e-01]],\n",
       "              \n",
       "                       [[-6.8333e-04, -7.8679e-02, -9.4042e-03],\n",
       "                        [ 5.0571e-02, -7.8951e-02,  1.8656e-02],\n",
       "                        [ 1.1881e-02,  4.9718e-02,  1.4869e-02]],\n",
       "              \n",
       "                       [[-5.3111e-01,  1.6878e-01, -6.8560e-01],\n",
       "                        [ 2.9050e-02,  9.4553e-01,  1.8327e-01],\n",
       "                        [-6.4223e-01,  1.1481e-01, -7.0310e-01]],\n",
       "              \n",
       "                       [[ 1.8490e-02, -1.2082e-01, -5.9709e-02],\n",
       "                        [-6.2457e-02, -1.2165e-01,  3.3194e-02],\n",
       "                        [ 1.3524e-02, -7.8736e-03, -1.2954e-01]],\n",
       "              \n",
       "                       [[-1.0366e-01,  6.7238e-02,  2.4851e-01],\n",
       "                        [-2.0996e-01, -9.1166e-02, -5.6530e-03],\n",
       "                        [-5.4048e-01, -2.7210e-01, -4.8631e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9178e-02, -8.8885e-02, -1.1046e-01],\n",
       "                        [-1.0525e-01, -6.3292e-02,  2.1496e-02],\n",
       "                        [ 1.5763e-02, -4.7206e-02, -1.0117e-01]],\n",
       "              \n",
       "                       [[ 3.9325e-03,  4.0726e-02,  6.4392e-03],\n",
       "                        [ 3.0198e-02, -2.6906e-02, -9.2713e-02],\n",
       "                        [ 3.3046e-04, -1.2968e-01, -9.0644e-02]],\n",
       "              \n",
       "                       [[-1.0851e-01,  2.0976e-02,  3.9115e-02],\n",
       "                        [-2.2246e-02, -7.4665e-02, -3.0787e-02],\n",
       "                        [ 7.4593e-02, -4.1834e-02, -5.1955e-02]],\n",
       "              \n",
       "                       [[ 1.6376e-01,  1.3658e-02,  7.5734e-02],\n",
       "                        [-5.3092e-02, -2.0774e-01, -1.1549e-01],\n",
       "                        [-7.3078e-02, -2.5859e-01, -1.3682e-01]],\n",
       "              \n",
       "                       [[-4.0245e-02, -1.4095e-01, -2.2369e-01],\n",
       "                        [-1.5870e-01, -1.6511e-01, -1.4474e-01],\n",
       "                        [-5.5213e-02, -5.7842e-02, -5.0082e-02]],\n",
       "              \n",
       "                       [[-1.9770e-01,  1.0728e-01,  4.6593e-02],\n",
       "                        [-1.5367e-01,  1.2436e-01,  6.7951e-02],\n",
       "                        [-2.1759e-01,  1.2411e-01,  1.4747e-01]],\n",
       "              \n",
       "                       [[-9.7692e-02, -4.2329e-02,  3.1829e-02],\n",
       "                        [-3.3981e-02, -1.5492e-01, -1.4503e-01],\n",
       "                        [ 4.2578e-02, -5.8993e-02,  9.9245e-02]],\n",
       "              \n",
       "                       [[-2.8153e-01,  1.7785e-02, -2.8790e-01],\n",
       "                        [-5.5914e-01, -2.3659e-01, -4.6404e-01],\n",
       "                        [ 2.5361e-01,  6.4224e-01,  2.6011e-01]],\n",
       "              \n",
       "                       [[-1.0548e-01, -3.7326e-02,  5.3370e-02],\n",
       "                        [-1.3538e-01, -3.1524e-03, -2.3561e-02],\n",
       "                        [-6.9067e-02, -9.9976e-02, -1.2327e-01]],\n",
       "              \n",
       "                       [[-9.5448e-02, -1.8957e-01, -1.0220e-01],\n",
       "                        [-1.7461e-01, -8.0557e-02, -9.4734e-02],\n",
       "                        [-1.0372e-01, -2.3085e-01, -2.8809e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0687e-02, -9.4448e-02, -6.9642e-02],\n",
       "                        [ 3.3636e-02,  1.7929e-02, -4.7291e-02],\n",
       "                        [-9.5396e-02,  3.4792e-02,  1.1421e-02]],\n",
       "              \n",
       "                       [[ 4.8575e-02, -9.2880e-02,  1.0254e-01],\n",
       "                        [-5.7651e-02, -1.0536e-01, -5.9725e-02],\n",
       "                        [ 4.5963e-02,  1.5818e-02, -9.2560e-02]],\n",
       "              \n",
       "                       [[-5.4263e-02, -1.2771e-03, -4.8727e-02],\n",
       "                        [ 3.4458e-02, -8.2677e-02, -8.9614e-02],\n",
       "                        [-1.8411e-03,  9.6864e-03, -9.2620e-02]],\n",
       "              \n",
       "                       [[ 4.1167e-02, -5.6518e-02, -4.2617e-02],\n",
       "                        [-1.1633e-01, -9.3224e-02,  1.7280e-02],\n",
       "                        [-8.1494e-04, -2.3272e-02, -5.5826e-02]],\n",
       "              \n",
       "                       [[ 2.0790e-02,  1.4938e-01,  2.3202e-01],\n",
       "                        [ 1.1219e-01,  7.5362e-03,  7.9592e-02],\n",
       "                        [ 1.8013e-01, -3.5582e-03,  1.9171e-02]],\n",
       "              \n",
       "                       [[ 4.7432e-02,  1.0098e-01,  1.0616e-01],\n",
       "                        [-5.6290e-02, -7.0299e-02,  8.1003e-02],\n",
       "                        [-2.2299e-02,  3.2873e-03,  1.0560e-01]],\n",
       "              \n",
       "                       [[-3.0020e-02, -5.7867e-03,  5.6606e-02],\n",
       "                        [ 5.3820e-02,  4.2627e-02,  5.1427e-02],\n",
       "                        [-6.4858e-02, -1.3519e-02,  8.6926e-02]],\n",
       "              \n",
       "                       [[-3.8056e-02,  1.5032e-02,  4.3169e-02],\n",
       "                        [ 1.6574e-02,  1.0848e-01,  6.0196e-02],\n",
       "                        [ 1.9932e-02, -2.2124e-02,  4.6657e-02]],\n",
       "              \n",
       "                       [[ 1.4968e-01,  1.7068e-01,  1.9480e-01],\n",
       "                        [ 1.2839e-01,  2.4961e-01,  1.5716e-01],\n",
       "                        [ 6.4489e-02,  2.5296e-01,  8.7072e-02]],\n",
       "              \n",
       "                       [[-7.2189e-02, -1.4110e-01,  8.2444e-02],\n",
       "                        [-1.0638e-01, -1.7664e-01, -9.9348e-02],\n",
       "                        [-7.4431e-02, -9.7314e-02, -4.1856e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2744e-01, -5.8532e-02, -1.2629e-01],\n",
       "                        [-4.0101e-03,  1.5447e-02, -1.2384e-01],\n",
       "                        [-2.6497e-02, -2.8465e-02, -1.1823e-01]],\n",
       "              \n",
       "                       [[-1.6210e-01, -5.6390e-02, -5.4039e-02],\n",
       "                        [-9.7749e-02, -7.0420e-02, -2.0746e-01],\n",
       "                        [-3.5216e-02, -7.1055e-02, -2.4512e-02]],\n",
       "              \n",
       "                       [[ 2.3704e-02, -7.7207e-02, -2.7694e-02],\n",
       "                        [-2.2708e-03,  2.9717e-02, -5.4592e-02],\n",
       "                        [ 1.2333e-02,  4.6958e-03, -7.9930e-02]],\n",
       "              \n",
       "                       [[-2.0302e+00, -1.0199e+00, -2.1495e+00],\n",
       "                        [-5.1848e-01,  6.0171e-01, -1.0117e+00],\n",
       "                        [-1.3662e+00, -3.9846e-01, -1.7251e+00]],\n",
       "              \n",
       "                       [[-1.1815e-01, -5.9071e-02, -1.5746e-01],\n",
       "                        [-6.1902e-02, -2.3125e-01, -2.8388e-01],\n",
       "                        [-5.6392e-02, -1.1896e-01, -1.3619e-01]],\n",
       "              \n",
       "                       [[-5.8247e-01, -5.9123e-01, -6.6660e-01],\n",
       "                        [-3.4590e-01, -2.1260e-01, -4.4623e-01],\n",
       "                        [-3.5625e-01, -2.7770e-01, -2.3735e-01]],\n",
       "              \n",
       "                       [[-2.0901e-01, -8.7097e-02, -9.8836e-02],\n",
       "                        [-3.5945e-02, -4.4987e-02, -1.5664e-01],\n",
       "                        [-1.8082e-01, -1.3528e-01, -1.8777e-01]],\n",
       "              \n",
       "                       [[-1.1120e-01, -1.4167e-01,  2.6761e-03],\n",
       "                        [ 2.9335e-02, -7.3098e-02, -9.0328e-02],\n",
       "                        [ 6.6347e-02,  2.6413e-02, -1.6591e-02]],\n",
       "              \n",
       "                       [[-2.4435e-02, -1.3393e-01, -3.7932e-02],\n",
       "                        [-5.5616e-02, -6.4647e-02, -2.3186e-02],\n",
       "                        [-3.2720e-02,  4.3970e-02, -1.0477e-01]],\n",
       "              \n",
       "                       [[-2.9307e-01, -2.4479e-01, -2.7373e-01],\n",
       "                        [-2.9793e-01, -1.6205e-01, -2.5215e-01],\n",
       "                        [-2.5507e-01, -1.1304e-01, -2.4407e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.0353e-02, -1.1296e-01,  1.9175e-02],\n",
       "                        [-5.2011e-02, -9.9946e-02,  5.1690e-02],\n",
       "                        [-5.1437e-02,  2.4101e-02, -8.6735e-02]],\n",
       "              \n",
       "                       [[-7.6519e-02,  2.9292e-02, -8.2031e-02],\n",
       "                        [-3.3504e-02,  6.2187e-02, -7.2335e-02],\n",
       "                        [ 3.8965e-02,  1.1039e-02, -9.9774e-02]],\n",
       "              \n",
       "                       [[-2.8744e-02,  3.8706e-03, -2.4371e-03],\n",
       "                        [ 8.2255e-02, -8.4131e-02, -5.1679e-02],\n",
       "                        [ 2.7489e-02, -4.5773e-02,  7.1077e-02]],\n",
       "              \n",
       "                       [[ 8.4072e-02, -2.0215e-02,  1.0251e-01],\n",
       "                        [ 2.4608e-01,  1.0417e-01,  8.4079e-02],\n",
       "                        [ 1.3177e-01,  2.8440e-01,  5.5932e-02]],\n",
       "              \n",
       "                       [[ 6.3380e-02, -9.0338e-02, -1.2655e-01],\n",
       "                        [-1.3258e-01,  3.0352e-02, -7.8821e-02],\n",
       "                        [-1.3237e-01, -1.2608e-01, -6.3441e-02]],\n",
       "              \n",
       "                       [[ 2.0979e-02, -1.1310e-01, -1.3341e-01],\n",
       "                        [-9.1562e-02,  7.0233e-02, -3.8469e-02],\n",
       "                        [-1.2702e-01,  6.8169e-02, -7.5055e-02]],\n",
       "              \n",
       "                       [[ 9.6072e-02,  1.0013e-01, -6.8704e-02],\n",
       "                        [ 1.2785e-01, -1.6573e-03,  1.6600e-02],\n",
       "                        [-4.2865e-02,  3.8428e-02,  9.4680e-02]],\n",
       "              \n",
       "                       [[-7.2555e-01,  3.2675e-01, -8.1612e-01],\n",
       "                        [-8.0390e-01,  3.5800e-01, -9.3591e-01],\n",
       "                        [-5.5676e-01,  2.2619e-01, -5.3744e-01]],\n",
       "              \n",
       "                       [[ 1.7366e-02, -7.0937e-03,  3.2038e-02],\n",
       "                        [-7.7229e-02, -3.1300e-03, -7.5520e-02],\n",
       "                        [ 4.9178e-02,  3.2313e-02, -1.3655e-02]],\n",
       "              \n",
       "                       [[-1.6824e-01, -7.9129e-03, -7.5992e-02],\n",
       "                        [-1.8179e-01, -1.7783e-01, -1.5193e-01],\n",
       "                        [-1.8962e-01, -1.7017e-01, -9.0765e-02]]]])),\n",
       "             ('decoder.5.bias',\n",
       "              tensor([-0.0596, -0.0944, -0.0546,  0.1436, -0.0699, -0.1270, -0.2137,  0.3603,\n",
       "                      -0.0125, -0.1154])),\n",
       "             ('decoder.8.weight',\n",
       "              tensor([[[[ 0.1183,  0.1084, -0.1415],\n",
       "                        [-0.2062,  0.2777, -0.2057],\n",
       "                        [-0.2459, -0.0805, -0.1201]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0867,  0.0964,  0.0945],\n",
       "                        [-0.1085, -0.0725, -0.1480],\n",
       "                        [ 0.1211,  0.1594,  0.0199]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3408,  0.0936,  0.2426],\n",
       "                        [ 0.1433, -0.2352,  0.2168],\n",
       "                        [-0.3075,  0.0293,  0.0266]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2657,  0.2815,  0.2446],\n",
       "                        [ 0.0426,  0.7003,  0.1344],\n",
       "                        [-0.2393,  0.1460, -0.3384]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3940, -0.0061, -0.0369],\n",
       "                        [-0.0328, -0.1529,  0.2425],\n",
       "                        [ 0.0180,  0.1054,  0.2417]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1256,  0.4337, -0.0341],\n",
       "                        [-0.0031,  0.0132,  0.3869],\n",
       "                        [ 0.1759,  0.0183,  0.1364]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2606,  0.3106,  0.0449],\n",
       "                        [-0.0394,  0.0705, -0.0508],\n",
       "                        [-0.1243,  0.4067,  0.4578]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0658,  0.3179, -0.1709],\n",
       "                        [ 0.0427,  0.1270,  0.3466],\n",
       "                        [-0.0377,  0.3245, -0.0891]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1021,  0.1818, -0.2113],\n",
       "                        [ 0.3005,  0.2685, -0.0024],\n",
       "                        [ 0.0460, -0.2118, -0.1211]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0754, -0.1045, -0.1893],\n",
       "                        [ 0.0752,  0.1357, -0.0157],\n",
       "                        [ 0.4465,  0.2353, -0.1001]]]])),\n",
       "             ('decoder.8.bias', tensor([0.2475]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
